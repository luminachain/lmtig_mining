

#include "private/autogen/config.h"

#define _ATFILE_SOURCE
#include <assert.h>
#include <sys/types.h>
#ifdef HAVE_DIRENT_H
#include <dirent.h>
#endif
#ifdef HAVE_UNISTD_H
#include <unistd.h>
#endif
#include <string.h>
#include <errno.h>
#include <stdio.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <limits.h>
#include <float.h>

#include "hwloc.h"
#include "private/private.h"
#include "private/debug.h"
#include "private/misc.h"

#ifdef HAVE_MACH_MACH_INIT_H
#include <mach/mach_init.h>
#endif
#ifdef HAVE_MACH_INIT_H
#include <mach_init.h>
#endif
#ifdef HAVE_MACH_MACH_HOST_H
#include <mach/mach_host.h>
#endif

#ifdef HAVE_SYS_PARAM_H
#include <sys/param.h>
#endif

#ifdef HAVE_SYS_SYSCTL_H
#include <sys/sysctl.h>
#endif

#ifdef HWLOC_WIN_SYS
#include <windows.h>
#endif


#ifdef HWLOC_HAVE_LEVELZERO

#if HWLOC_HAVE_ATTRIBUTE_CONSTRUCTOR
static void hwloc_constructor(void) __attribute__((constructor));
static void hwloc_constructor(void)
{
  if (!getenv("ZES_ENABLE_SYSMAN"))
#ifdef HWLOC_WIN_SYS
    putenv("ZES_ENABLE_SYSMAN=1");
#else
    setenv("ZES_ENABLE_SYSMAN", "1", 1);
#endif
}
#endif
#ifdef HWLOC_WIN_SYS
BOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD fdwReason, LPVOID lpReserved)
{
  if (fdwReason == DLL_PROCESS_ATTACH) {
    if (!getenv("ZES_ENABLE_SYSMAN"))
      
      putenv((char *) "ZES_ENABLE_SYSMAN=1");
  }
  return TRUE;
}
#endif
#endif 


unsigned hwloc_get_api_version(void)
{
  return HWLOC_API_VERSION;
}

int hwloc_topology_abi_check(hwloc_topology_t topology)
{
  return topology->topology_abi != HWLOC_TOPOLOGY_ABI ? -1 : 0;
}


int hwloc_hide_errors(void)
{
  static int hide = 1; 
  static int checked = 0;
  if (!checked) {
    const char *envvar = getenv("HWLOC_HIDE_ERRORS");
    if (envvar) {
      hide = atoi(envvar);
#ifdef HWLOC_DEBUG
    } else {
      
      envvar = getenv("HWLOC_DEBUG_VERBOSE");
      if (!envvar || atoi(envvar))
        hide = 0;
#endif
    }
    checked = 1;
  }
  return hide;
}



static void
report_insert_error_format_obj(char *buf, size_t buflen, hwloc_obj_t obj)
{
  char typestr[64];
  char *cpusetstr;
  char *nodesetstr = NULL;
  char indexstr[64] = "";
  char groupstr[64] = "";

  hwloc_obj_type_snprintf(typestr, sizeof(typestr), obj, 0);
  hwloc_bitmap_asprintf(&cpusetstr, obj->cpuset);
  if (obj->os_index != HWLOC_UNKNOWN_INDEX)
    snprintf(indexstr, sizeof(indexstr), "P#%u ", obj->os_index);
  if (obj->type == HWLOC_OBJ_GROUP)
    snprintf(groupstr, sizeof(groupstr), "groupkind %u-%u ", obj->attr->group.kind, obj->attr->group.subkind);
  if (obj->nodeset) 
    hwloc_bitmap_asprintf(&nodesetstr, obj->nodeset);
  snprintf(buf, buflen, "%s (%s%s%s%s%scpuset %s%s%s)",
           typestr,
           indexstr,
           obj->subtype ? "subtype " : "", obj->subtype ? obj->subtype : "", obj->subtype ? " " : "",
           groupstr,
           cpusetstr,
           nodesetstr ? " nodeset " : "", nodesetstr ? nodesetstr : "");
  free(cpusetstr);
  free(nodesetstr);
}

static void report_insert_error(hwloc_obj_t new, hwloc_obj_t old, const char *msg, const char *reason)
{
  static int reported = 0;

  if (reason && !reported && HWLOC_SHOW_CRITICAL_ERRORS()) {
    char newstr[512];
    char oldstr[512];
    report_insert_error_format_obj(newstr, sizeof(newstr), new);
    report_insert_error_format_obj(oldstr, sizeof(oldstr), old);

    fprintf(stderr, "****************************************************************************\n");
    fprintf(stderr, "* hwloc %s received invalid information from the operating system.\n", HWLOC_VERSION);
    fprintf(stderr, "*\n");
    fprintf(stderr, "* Failed with error: %s\n", msg);
    fprintf(stderr, "* while inserting %s\n", newstr);
    fprintf(stderr, "* at %s\n", oldstr);
    fprintf(stderr, "* coming from: %s\n", reason);
    fprintf(stderr, "*\n");
    fprintf(stderr, "* The following FAQ entry in the hwloc documentation may help:\n");
    fprintf(stderr, "*   What should I do when hwloc reports \"operating system\" warnings?\n");
    fprintf(stderr, "* Otherwise please report this error message to the hwloc user's mailing list,\n");
#ifdef HWLOC_LINUX_SYS
    fprintf(stderr, "* along with the files generated by the hwloc-gather-topology script.\n");
#else
    fprintf(stderr, "* along with any relevant topology information from your platform.\n");
#endif
    fprintf(stderr, "* \n");
    fprintf(stderr, "* hwloc will now ignore this invalid topology information and continue.\n");
    fprintf(stderr, "****************************************************************************\n");
    reported = 1;
  }
}

#if defined(HAVE_SYSCTLBYNAME)
int hwloc_get_sysctlbyname(const char *name, int64_t *ret)
{
  union {
    int32_t i32;
    int64_t i64;
  } n;
  size_t size = sizeof(n);
  if (sysctlbyname(name, &n, &size, NULL, 0))
    return -1;
  switch (size) {
    case sizeof(n.i32):
      *ret = n.i32;
      break;
    case sizeof(n.i64):
      *ret = n.i64;
      break;
    default:
      return -1;
  }
  return 0;
}
#endif

#if defined(HAVE_SYSCTL)
int hwloc_get_sysctl(int name[], unsigned namelen, int64_t *ret)
{
  union {
    int32_t i32;
    int64_t i64;
  } n;
  size_t size = sizeof(n);
  if (sysctl(name, namelen, &n, &size, NULL, 0))
    return -1;
  switch (size) {
    case sizeof(n.i32):
      *ret = n.i32;
      break;
    case sizeof(n.i64):
      *ret = n.i64;
      break;
    default:
      return -1;
  }
  return 0;
}
#endif


#ifndef HWLOC_WIN_SYS 
int
hwloc_fallback_nbprocessors(unsigned flags) {
  int n;

  if (flags & HWLOC_FALLBACK_NBPROCESSORS_INCLUDE_OFFLINE) {
    
#if HAVE_DECL__SC_NPROCESSORS_CONF
    n = sysconf(_SC_NPROCESSORS_CONF);
#elif HAVE_DECL__SC_NPROC_CONF
    n = sysconf(_SC_NPROC_CONF);
#else
    n = -1;
#endif
    if (n != -1)
      return n;
  }

  
#if HAVE_DECL__SC_NPROCESSORS_ONLN
  n = sysconf(_SC_NPROCESSORS_ONLN);
#elif HAVE_DECL__SC_NPROC_ONLN
  n = sysconf(_SC_NPROC_ONLN);
#elif HAVE_DECL__SC_NPROCESSORS_CONF
  n = sysconf(_SC_NPROCESSORS_CONF);
#elif HAVE_DECL__SC_NPROC_CONF
  n = sysconf(_SC_NPROC_CONF);
#elif defined(HAVE_HOST_INFO) && HAVE_HOST_INFO
  struct host_basic_info info;
  mach_msg_type_number_t count = HOST_BASIC_INFO_COUNT;
  host_info(mach_host_self(), HOST_BASIC_INFO, (integer_t*) &info, &count);
  n = info.avail_cpus;
#elif defined(HAVE_SYSCTLBYNAME)
  int64_t nn;
  if (hwloc_get_sysctlbyname("hw.ncpu", &nn))
    nn = -1;
  n = nn;
#elif defined(HAVE_SYSCTL) && HAVE_DECL_CTL_HW && HAVE_DECL_HW_NCPU
  static int name[2] = {CTL_HW, HW_NCPU};
  int64_t nn;
  if (hwloc_get_sysctl(name, sizeof(name)/sizeof(*name), &nn))
    n = -1;
  n = nn;
#else
#ifdef __GNUC__
#warning No known way to discover number of available processors on this system
#endif
  n = -1;
#endif
  return n;
}

int64_t
hwloc_fallback_memsize(void) {
  int64_t size;
#if defined(HAVE_HOST_INFO) && HAVE_HOST_INFO
  struct host_basic_info info;
  mach_msg_type_number_t count = HOST_BASIC_INFO_COUNT;
  host_info(mach_host_self(), HOST_BASIC_INFO, (integer_t*) &info, &count);
  size = info.memory_size;
#elif defined(HAVE_SYSCTL) && HAVE_DECL_CTL_HW && (HAVE_DECL_HW_REALMEM64 || HAVE_DECL_HW_MEMSIZE64 || HAVE_DECL_HW_PHYSMEM64 || HAVE_DECL_HW_USERMEM64 || HAVE_DECL_HW_REALMEM || HAVE_DECL_HW_MEMSIZE || HAVE_DECL_HW_PHYSMEM || HAVE_DECL_HW_USERMEM)
#if HAVE_DECL_HW_MEMSIZE64
  static int name[2] = {CTL_HW, HW_MEMSIZE64};
#elif HAVE_DECL_HW_REALMEM64
  static int name[2] = {CTL_HW, HW_REALMEM64};
#elif HAVE_DECL_HW_PHYSMEM64
  static int name[2] = {CTL_HW, HW_PHYSMEM64};
#elif HAVE_DECL_HW_USERMEM64
  static int name[2] = {CTL_HW, HW_USERMEM64};
#elif HAVE_DECL_HW_MEMSIZE
  static int name[2] = {CTL_HW, HW_MEMSIZE};
#elif HAVE_DECL_HW_REALMEM
  static int name[2] = {CTL_HW, HW_REALMEM};
#elif HAVE_DECL_HW_PHYSMEM
  static int name[2] = {CTL_HW, HW_PHYSMEM};
#elif HAVE_DECL_HW_USERMEM
  static int name[2] = {CTL_HW, HW_USERMEM};
#endif
  if (hwloc_get_sysctl(name, sizeof(name)/sizeof(*name), &size))
    size = -1;
#elif defined(HAVE_SYSCTLBYNAME)
  if (hwloc_get_sysctlbyname("hw.memsize", &size) &&
      hwloc_get_sysctlbyname("hw.realmem", &size) &&
      hwloc_get_sysctlbyname("hw.physmem", &size) &&
      hwloc_get_sysctlbyname("hw.usermem", &size))
      size = -1;
#else
  size = -1;
#endif
  return size;
}
#endif 


void
hwloc_setup_pu_level(struct hwloc_topology *topology,
		     unsigned nb_pus)
{
  struct hwloc_obj *obj;
  unsigned oscpu,cpu;

  hwloc_debug("%s", "\n\n * CPU cpusets *\n\n");
  for (cpu=0,oscpu=0; cpu<nb_pus; oscpu++)
    {
      obj = hwloc_alloc_setup_object(topology, HWLOC_OBJ_PU, oscpu);
      obj->cpuset = hwloc_bitmap_alloc();
      hwloc_bitmap_only(obj->cpuset, oscpu);

      hwloc_debug_2args_bitmap("cpu %u (os %u) has cpuset %s\n",
		 cpu, oscpu, obj->cpuset);
      hwloc__insert_object_by_cpuset(topology, NULL, obj, "core:pulevel");

      cpu++;
    }
}


#define for_each_child_safe(child, parent, pchild) \
  for (pchild = &(parent)->first_child, child = *pchild; \
       child; \
        \
       (*pchild == child ? pchild = &(child->next_sibling) : NULL), \
        \
        child = *pchild)
#define for_each_memory_child_safe(child, parent, pchild) \
  for (pchild = &(parent)->memory_first_child, child = *pchild; \
       child; \
        \
       (*pchild == child ? pchild = &(child->next_sibling) : NULL), \
        \
        child = *pchild)
#define for_each_io_child_safe(child, parent, pchild) \
  for (pchild = &(parent)->io_first_child, child = *pchild; \
       child; \
        \
       (*pchild == child ? pchild = &(child->next_sibling) : NULL), \
        \
        child = *pchild)
#define for_each_misc_child_safe(child, parent, pchild) \
  for (pchild = &(parent)->misc_first_child, child = *pchild; \
       child; \
        \
       (*pchild == child ? pchild = &(child->next_sibling) : NULL), \
        \
        child = *pchild)

#ifdef HWLOC_DEBUG

static void
hwloc_debug_print_object(int indent __hwloc_attribute_unused, hwloc_obj_t obj)
{
  char type[64], idx[12], attr[1024], *cpuset = NULL;
  hwloc_debug("%*s", 2*indent, "");
  hwloc_obj_type_snprintf(type, sizeof(type), obj, 1);
  if (obj->os_index != HWLOC_UNKNOWN_INDEX)
    snprintf(idx, sizeof(idx), "#%u", obj->os_index);
  else
    *idx = '\0';
  hwloc_obj_attr_snprintf(attr, sizeof(attr), obj, " ", 1);
  hwloc_debug("%s%s%s%s%s", type, idx, *attr ? "(" : "", attr, *attr ? ")" : "");
  if (obj->name)
    hwloc_debug(" name \"%s\"", obj->name);
  if (obj->subtype)
    hwloc_debug(" subtype \"%s\"", obj->subtype);
  if (obj->cpuset) {
    hwloc_bitmap_asprintf(&cpuset, obj->cpuset);
    hwloc_debug(" cpuset %s", cpuset);
    free(cpuset);
  }
  if (obj->complete_cpuset) {
    hwloc_bitmap_asprintf(&cpuset, obj->complete_cpuset);
    hwloc_debug(" complete %s", cpuset);
    free(cpuset);
  }
  if (obj->nodeset) {
    hwloc_bitmap_asprintf(&cpuset, obj->nodeset);
    hwloc_debug(" nodeset %s", cpuset);
    free(cpuset);
  }
  if (obj->complete_nodeset) {
    hwloc_bitmap_asprintf(&cpuset, obj->complete_nodeset);
    hwloc_debug(" completeN %s", cpuset);
    free(cpuset);
  }
  if (obj->arity)
    hwloc_debug(" arity %u", obj->arity);
  hwloc_debug("%s", "\n");
}

static void
hwloc_debug_print_objects(int indent __hwloc_attribute_unused, hwloc_obj_t obj)
{
  if (hwloc_debug_enabled() >= 2) {
    hwloc_obj_t child;
    hwloc_debug_print_object(indent, obj);
    for_each_child (child, obj)
      hwloc_debug_print_objects(indent + 1, child);
    for_each_memory_child (child, obj)
      hwloc_debug_print_objects(indent + 1, child);
    for_each_io_child (child, obj)
      hwloc_debug_print_objects(indent + 1, child);
    for_each_misc_child (child, obj)
      hwloc_debug_print_objects(indent + 1, child);
  }
}
#else 
#define hwloc_debug_print_object(indent, obj) do {  } while (0)
#define hwloc_debug_print_objects(indent, obj) do {  } while (0)
#endif 

int hwloc_obj_set_subtype(hwloc_topology_t topology __hwloc_attribute_unused, hwloc_obj_t obj, const char *subtype)
{
  char *new = NULL;
  if (subtype) {
    new = strdup(subtype);
    if (!new)
      return -1;
  }
  if (obj->subtype)
    free(obj->subtype);
  obj->subtype = new;
  return 0;
}

void hwloc__free_infos(struct hwloc_info_s *infos, unsigned count)
{
  unsigned i;
  for(i=0; i<count; i++) {
    free(infos[i].name);
    free(infos[i].value);
  }
  free(infos);
}

int hwloc__add_info(struct hwloc_info_s **infosp, unsigned *countp, const char *name, const char *value)
{
  unsigned count = *countp;
  struct hwloc_info_s *infos = *infosp;
#define OBJECT_INFO_ALLOC 8
  
  unsigned alloccount = (count + 1 + (OBJECT_INFO_ALLOC-1)) & ~(OBJECT_INFO_ALLOC-1);
  if (count != alloccount) {
    struct hwloc_info_s *tmpinfos = realloc(infos, alloccount*sizeof(*infos));
    if (!tmpinfos)
      
      goto out_with_array;
    *infosp = infos = tmpinfos;
  }
  infos[count].name = strdup(name);
  if (!infos[count].name)
    goto out_with_array;
  infos[count].value = strdup(value);
  if (!infos[count].value)
    goto out_with_name;
  *countp = count+1;
  return 0;

 out_with_name:
  free(infos[count].name);
 out_with_array:
  
  return -1;
}

int hwloc__add_info_nodup(struct hwloc_info_s **infosp, unsigned *countp,
			  const char *name, const char *value,
			  int replace)
{
  struct hwloc_info_s *infos = *infosp;
  unsigned count = *countp;
  unsigned i;
  for(i=0; i<count; i++) {
    if (!strcmp(infos[i].name, name)) {
      if (replace) {
	char *new = strdup(value);
	if (!new)
	  return -1;
	free(infos[i].value);
	infos[i].value = new;
      }
      return 0;
    }
  }
  return hwloc__add_info(infosp, countp, name, value);
}

int hwloc__move_infos(struct hwloc_info_s **dst_infosp, unsigned *dst_countp,
		      struct hwloc_info_s **src_infosp, unsigned *src_countp)
{
  unsigned dst_count = *dst_countp;
  struct hwloc_info_s *dst_infos = *dst_infosp;
  unsigned src_count = *src_countp;
  struct hwloc_info_s *src_infos = *src_infosp;
  unsigned i;
#define OBJECT_INFO_ALLOC 8
  
  unsigned alloccount = (dst_count + src_count + (OBJECT_INFO_ALLOC-1)) & ~(OBJECT_INFO_ALLOC-1);
  if (dst_count != alloccount) {
    struct hwloc_info_s *tmp_infos = realloc(dst_infos, alloccount*sizeof(*dst_infos));
    if (!tmp_infos)
      
      goto drop;
    dst_infos = tmp_infos;
  }
  for(i=0; i<src_count; i++, dst_count++) {
    dst_infos[dst_count].name = src_infos[i].name;
    dst_infos[dst_count].value = src_infos[i].value;
  }
  *dst_infosp = dst_infos;
  *dst_countp = dst_count;
  free(src_infos);
  *src_infosp = NULL;
  *src_countp = 0;
  return 0;

 drop:
  
  for(i=0; i<src_count; i++) {
    free(src_infos[i].name);
    free(src_infos[i].value);
  }
  free(src_infos);
  *src_infosp = NULL;
  *src_countp = 0;
  return -1;
}

int hwloc_obj_add_info(hwloc_obj_t obj, const char *name, const char *value)
{
  return hwloc__add_info(&obj->infos, &obj->infos_count, name, value);
}


int hwloc__tma_dup_infos(struct hwloc_tma *tma,
                         struct hwloc_info_s **newip, unsigned *newcp,
                         struct hwloc_info_s *oldi, unsigned oldc)
{
  struct hwloc_info_s *newi;
  unsigned i, j;
  newi = hwloc_tma_calloc(tma, oldc * sizeof(*newi));
  if (!newi)
    return -1;
  for(i=0; i<oldc; i++) {
    newi[i].name = hwloc_tma_strdup(tma, oldi[i].name);
    newi[i].value = hwloc_tma_strdup(tma, oldi[i].value);
    if (!newi[i].name || !newi[i].value)
      goto failed;
  }
  *newip = newi;
  *newcp = oldc;
  return 0;

 failed:
  assert(!tma || !tma->dontfree); 
  for(j=0; j<=i; j++) {
    free(newi[i].name);
    free(newi[i].value);
  }
  free(newi);
  *newip = NULL;
  return -1;
}

static void
hwloc__free_object_contents(hwloc_obj_t obj)
{
  switch (obj->type) {
  case HWLOC_OBJ_NUMANODE:
    free(obj->attr->numanode.page_types);
    break;
  default:
    break;
  }
  hwloc__free_infos(obj->infos, obj->infos_count);
  free(obj->attr);
  free(obj->children);
  free(obj->subtype);
  free(obj->name);
  hwloc_bitmap_free(obj->cpuset);
  hwloc_bitmap_free(obj->complete_cpuset);
  hwloc_bitmap_free(obj->nodeset);
  hwloc_bitmap_free(obj->complete_nodeset);
}


void
hwloc_free_unlinked_object(hwloc_obj_t obj)
{
  hwloc__free_object_contents(obj);
  free(obj);
}


static void
hwloc_replace_linked_object(hwloc_obj_t old, hwloc_obj_t new)
{
  
  hwloc__free_object_contents(old);
  
  new->parent = old->parent;
  new->next_sibling = old->next_sibling;
  new->first_child = old->first_child;
  new->memory_first_child = old->memory_first_child;
  new->io_first_child = old->io_first_child;
  new->misc_first_child = old->misc_first_child;
  
  memcpy(old, new, sizeof(*old));
  
  memset(new, 0,sizeof(*new));
}


static void
unlink_and_free_object_and_children(hwloc_obj_t *pobj)
{
  hwloc_obj_t obj = *pobj, child, *pchild;

  for_each_child_safe(child, obj, pchild)
    unlink_and_free_object_and_children(pchild);
  for_each_memory_child_safe(child, obj, pchild)
    unlink_and_free_object_and_children(pchild);
  for_each_io_child_safe(child, obj, pchild)
    unlink_and_free_object_and_children(pchild);
  for_each_misc_child_safe(child, obj, pchild)
    unlink_and_free_object_and_children(pchild);

  *pobj = obj->next_sibling;
  hwloc_free_unlinked_object(obj);
}


void
hwloc_free_object_and_children(hwloc_obj_t obj)
{
  if (obj)
    unlink_and_free_object_and_children(&obj);
}


void
hwloc_free_object_siblings_and_children(hwloc_obj_t obj)
{
  while (obj)
    unlink_and_free_object_and_children(&obj);
}


static hwloc_obj_t *
insert_siblings_list(hwloc_obj_t *firstp, hwloc_obj_t firstnew, hwloc_obj_t newparent)
{
  hwloc_obj_t tmp;
  assert(firstnew);
  *firstp = tmp = firstnew;
  tmp->parent = newparent;
  while (tmp->next_sibling) {
    tmp = tmp->next_sibling;
    tmp->parent = newparent;
  }
  return &tmp->next_sibling;
}


static void
prepend_siblings_list(hwloc_obj_t *firstp, hwloc_obj_t firstnew, hwloc_obj_t newparent)
{
  hwloc_obj_t *tmpp, tmp, last;
  unsigned length;

  
  for(length = 0, tmpp = &firstnew, last = NULL ; *tmpp; length++, last = *tmpp, tmpp = &((*tmpp)->next_sibling))
    (*tmpp)->parent = newparent;

  
  for(tmp = *firstp; tmp; tmp = tmp->next_sibling)
    tmp->sibling_rank += length; 

  
  *tmpp = *firstp;
  if (*firstp)
    (*firstp)->prev_sibling = last;

  
  *firstp = firstnew;
}


static void
append_siblings_list(hwloc_obj_t *firstp, hwloc_obj_t firstnew, hwloc_obj_t newparent)
{
  hwloc_obj_t *tmpp, tmp, last;
  unsigned length;

  
  for(length = 0, tmpp = firstp, last = NULL ; *tmpp; length++, last = *tmpp, tmpp = &((*tmpp)->next_sibling));

  
  for(tmp = firstnew; tmp; tmp = tmp->next_sibling) {
    tmp->parent = newparent;
    tmp->sibling_rank += length; 
  }

  
  *tmpp = firstnew;
  if (firstnew)
    firstnew->prev_sibling = last;
}


static void
unlink_and_free_single_object(hwloc_obj_t *pparent)
{
  hwloc_obj_t old = *pparent;
  hwloc_obj_t *lastp;

  if (old->type == HWLOC_OBJ_MISC) {
    

    
    assert(!old->first_child);
    
    assert(!old->memory_first_child);
    
    assert(!old->io_first_child);

    if (old->misc_first_child)
      
      lastp = insert_siblings_list(pparent, old->misc_first_child, old->parent);
    else
      lastp = pparent;
    
    *lastp = old->next_sibling;

  } else if (hwloc__obj_type_is_io(old->type)) {
    

    
    assert(!old->first_child);
    
    assert(!old->memory_first_child);

    if (old->io_first_child)
      
      lastp = insert_siblings_list(pparent, old->io_first_child, old->parent);
    else
      lastp = pparent;
    
    *lastp = old->next_sibling;

    
    if (old->misc_first_child)
      append_siblings_list(&old->parent->misc_first_child, old->misc_first_child, old->parent);

  } else if (hwloc__obj_type_is_memory(old->type)) {
    

    
    assert(!old->first_child);
    
    assert(!old->io_first_child);

    if (old->memory_first_child)
      
      lastp = insert_siblings_list(pparent, old->memory_first_child, old->parent);
    else
      lastp = pparent;
    
    *lastp = old->next_sibling;

    
    if (old->misc_first_child)
      append_siblings_list(&old->parent->misc_first_child, old->misc_first_child, old->parent);

  } else {
    

    if (old->first_child)
      
      lastp = insert_siblings_list(pparent, old->first_child, old->parent);
    else
      lastp = pparent;
    
    *lastp = old->next_sibling;

    
    if (old->memory_first_child)
      append_siblings_list(&old->parent->memory_first_child, old->memory_first_child, old->parent);
    if (old->io_first_child)
      append_siblings_list(&old->parent->io_first_child, old->io_first_child, old->parent);
    if (old->misc_first_child)
      append_siblings_list(&old->parent->misc_first_child, old->misc_first_child, old->parent);
  }

  hwloc_free_unlinked_object(old);
}


static int
hwloc__duplicate_object(struct hwloc_topology *newtopology,
			struct hwloc_obj *newparent,
			struct hwloc_obj *newobj,
			struct hwloc_obj *src)
{
  struct hwloc_tma *tma = newtopology->tma;
  hwloc_obj_t *level;
  unsigned level_width;
  size_t len;
  unsigned i;
  hwloc_obj_t child, prev;
  int err = 0;

  
  assert(!newparent == !!newobj);

  if (!newobj) {
    newobj = hwloc_alloc_setup_object(newtopology, src->type, src->os_index);
    if (!newobj)
      return -1;
  }

  
  newobj->logical_index = src->logical_index;
  newobj->depth = src->depth;
  newobj->sibling_rank = src->sibling_rank;

  newobj->type = src->type;
  newobj->os_index = src->os_index;
  newobj->gp_index = src->gp_index;
  newobj->symmetric_subtree = src->symmetric_subtree;

  if (src->name)
    newobj->name = hwloc_tma_strdup(tma, src->name);
  if (src->subtype)
    newobj->subtype = hwloc_tma_strdup(tma, src->subtype);
  newobj->userdata = src->userdata;

  newobj->total_memory = src->total_memory;

  memcpy(newobj->attr, src->attr, sizeof(*newobj->attr));

  if (src->type == HWLOC_OBJ_NUMANODE && src->attr->numanode.page_types_len) {
    len = src->attr->numanode.page_types_len * sizeof(struct hwloc_memory_page_type_s);
    newobj->attr->numanode.page_types = hwloc_tma_malloc(tma, len);
    memcpy(newobj->attr->numanode.page_types, src->attr->numanode.page_types, len);
  }

  newobj->cpuset = hwloc_bitmap_tma_dup(tma, src->cpuset);
  newobj->complete_cpuset = hwloc_bitmap_tma_dup(tma, src->complete_cpuset);
  newobj->nodeset = hwloc_bitmap_tma_dup(tma, src->nodeset);
  newobj->complete_nodeset = hwloc_bitmap_tma_dup(tma, src->complete_nodeset);

  hwloc__tma_dup_infos(tma, &newobj->infos, &newobj->infos_count, src->infos, src->infos_count);

  
  if (src->depth < 0) {
    i = HWLOC_SLEVEL_FROM_DEPTH(src->depth);
    level = newtopology->slevels[i].objs;
    level_width = newtopology->slevels[i].nbobjs;
    
    if (!newobj->logical_index)
      newtopology->slevels[i].first = newobj;
    if (newobj->logical_index == newtopology->slevels[i].nbobjs - 1)
      newtopology->slevels[i].last = newobj;
  } else {
    level = newtopology->levels[src->depth];
    level_width = newtopology->level_nbobjects[src->depth];
  }
  
  assert(newobj->logical_index < level_width);
  level[newobj->logical_index] = newobj;
  
  if (newobj->logical_index > 0 && level[newobj->logical_index-1]) {
    newobj->prev_cousin = level[newobj->logical_index-1];
    level[newobj->logical_index-1]->next_cousin = newobj;
  }
  if (newobj->logical_index < level_width-1 && level[newobj->logical_index+1]) {
    newobj->next_cousin = level[newobj->logical_index+1];
    level[newobj->logical_index+1]->prev_cousin = newobj;
  }

  
  if (src->arity) {
    newobj->children = hwloc_tma_malloc(tma, src->arity * sizeof(*newobj->children));
    if (!newobj->children)
      return -1;
  }
  newobj->arity = src->arity;
  newobj->memory_arity = src->memory_arity;
  newobj->io_arity = src->io_arity;
  newobj->misc_arity = src->misc_arity;

  
  for_each_child(child, src) {
    err = hwloc__duplicate_object(newtopology, newobj, NULL, child);
    if (err < 0)
      goto out_with_children;
  }
  for_each_memory_child(child, src) {
    err = hwloc__duplicate_object(newtopology, newobj, NULL, child);
    if (err < 0)
      return err;
  }
  for_each_io_child(child, src) {
    err = hwloc__duplicate_object(newtopology, newobj, NULL, child);
    if (err < 0)
      goto out_with_children;
  }
  for_each_misc_child(child, src) {
    err = hwloc__duplicate_object(newtopology, newobj, NULL, child);
    if (err < 0)
      goto out_with_children;
  }

 out_with_children:

  
  if (!err) {
    
    if (newobj->arity) {
      newobj->children[0]->prev_sibling = NULL;
      for(i=1; i<newobj->arity; i++)
	newobj->children[i]->prev_sibling = newobj->children[i-1];
      newobj->last_child = newobj->children[newobj->arity-1];
    }
    if (newobj->memory_arity) {
      child = newobj->memory_first_child;
      prev = NULL;
      while (child) {
	child->prev_sibling = prev;
	prev = child;
	child = child->next_sibling;
      }
    }
    if (newobj->io_arity) {
      child = newobj->io_first_child;
      prev = NULL;
      while (child) {
	child->prev_sibling = prev;
	prev = child;
	child = child->next_sibling;
      }
    }
    if (newobj->misc_arity) {
      child = newobj->misc_first_child;
      prev = NULL;
      while (child) {
	child->prev_sibling = prev;
	prev = child;
	child = child->next_sibling;
      }
    }
  }

  

  if (newparent) {
    
    hwloc_insert_object_by_parent(newtopology, newparent, newobj);

    
    if (hwloc__obj_type_is_normal(newobj->type))
      newparent->children[newobj->sibling_rank] = newobj;
  }

  return err;
}

static int
hwloc__topology_init (struct hwloc_topology **topologyp, unsigned nblevels, struct hwloc_tma *tma);


int
hwloc__topology_dup(hwloc_topology_t *newp,
		    hwloc_topology_t old,
		    struct hwloc_tma *tma)
{
  hwloc_topology_t new;
  hwloc_obj_t newroot;
  hwloc_obj_t oldroot = hwloc_get_root_obj(old);
  unsigned i;
  int err;

  if (!old->is_loaded) {
    errno = EINVAL;
    return -1;
  }

  err = hwloc__topology_init(&new, old->nb_levels_allocated, tma);
  if (err < 0)
    goto out;

  new->flags = old->flags;
  memcpy(new->type_filter, old->type_filter, sizeof(old->type_filter));
  new->is_thissystem = old->is_thissystem;
  new->is_loaded = 1;
  new->pid = old->pid;
  new->next_gp_index = old->next_gp_index;

  memcpy(&new->binding_hooks, &old->binding_hooks, sizeof(old->binding_hooks));

  memcpy(new->support.discovery, old->support.discovery, sizeof(*old->support.discovery));
  memcpy(new->support.cpubind, old->support.cpubind, sizeof(*old->support.cpubind));
  memcpy(new->support.membind, old->support.membind, sizeof(*old->support.membind));
  memcpy(new->support.misc, old->support.misc, sizeof(*old->support.misc));

  new->allowed_cpuset = hwloc_bitmap_tma_dup(tma, old->allowed_cpuset);
  new->allowed_nodeset = hwloc_bitmap_tma_dup(tma, old->allowed_nodeset);

  new->userdata_export_cb = old->userdata_export_cb;
  new->userdata_import_cb = old->userdata_import_cb;
  new->userdata_not_decoded = old->userdata_not_decoded;

  assert(!old->machine_memory.local_memory);
  assert(!old->machine_memory.page_types_len);
  assert(!old->machine_memory.page_types);

  for(i = HWLOC_OBJ_TYPE_MIN; i < HWLOC_OBJ_TYPE_MAX; i++)
    new->type_depth[i] = old->type_depth[i];

  
  new->nb_levels = old->nb_levels;
  assert(new->nb_levels_allocated >= new->nb_levels);
  for(i=1  ; i<new->nb_levels; i++) {
    new->level_nbobjects[i] = old->level_nbobjects[i];
    new->levels[i] = hwloc_tma_calloc(tma, new->level_nbobjects[i] * sizeof(*new->levels[i]));
  }
  for(i=0; i<HWLOC_NR_SLEVELS; i++) {
    new->slevels[i].nbobjs = old->slevels[i].nbobjs;
    if (new->slevels[i].nbobjs)
      new->slevels[i].objs = hwloc_tma_calloc(tma, new->slevels[i].nbobjs * sizeof(*new->slevels[i].objs));
  }

  
  newroot = hwloc_get_root_obj(new);
  err = hwloc__duplicate_object(new, NULL, newroot, oldroot);
  if (err < 0)
    goto out_with_topology;

  err = hwloc_internal_distances_dup(new, old);
  if (err < 0)
    goto out_with_topology;

  err = hwloc_internal_memattrs_dup(new, old);
  if (err < 0)
    goto out_with_topology;

  err = hwloc_internal_cpukinds_dup(new, old);
  if (err < 0)
    goto out_with_topology;

  
  new->modified = 0;

  
  new->backends = NULL;
  new->get_pci_busid_cpuset_backend = NULL;

#ifndef HWLOC_DEBUG
  if (getenv("HWLOC_DEBUG_CHECK"))
#endif
    hwloc_topology_check(new);

  *newp = new;
  return 0;

 out_with_topology:
  assert(!tma || !tma->dontfree); 
  hwloc_topology_destroy(new);
 out:
  return -1;
}

int
hwloc_topology_dup(hwloc_topology_t *newp,
		   hwloc_topology_t old)
{
  return hwloc__topology_dup(newp, old, NULL);
}



static const unsigned obj_type_order[] = {
      0,
      4,
         14,
           18,
      12,
      10,
      8,
      7,
      6,
     13,
     11,
     9,
        1,
     3,
       15,
      16,
       17,
         19,
     2,
          5
};

#ifndef NDEBUG 
static const hwloc_obj_type_t obj_order_type[] = {
  HWLOC_OBJ_MACHINE,
  HWLOC_OBJ_GROUP,
  HWLOC_OBJ_MEMCACHE,
  HWLOC_OBJ_NUMANODE,
  HWLOC_OBJ_PACKAGE,
  HWLOC_OBJ_DIE,
  HWLOC_OBJ_L5CACHE,
  HWLOC_OBJ_L4CACHE,
  HWLOC_OBJ_L3CACHE,
  HWLOC_OBJ_L3ICACHE,
  HWLOC_OBJ_L2CACHE,
  HWLOC_OBJ_L2ICACHE,
  HWLOC_OBJ_L1CACHE,
  HWLOC_OBJ_L1ICACHE,
  HWLOC_OBJ_CORE,
  HWLOC_OBJ_BRIDGE,
  HWLOC_OBJ_PCI_DEVICE,
  HWLOC_OBJ_OS_DEVICE,
  HWLOC_OBJ_PU,
  HWLOC_OBJ_MISC 
};
#endif




static const int obj_type_priority[] = {
       90,
       40,
          60,
            100,
       20,
       20,
       20,
       20,
       20,
      19,
      19,
      19,
         0,
      100,
        0,
    100,
     100,
          0,
      19,
           30
};

int hwloc_compare_types (hwloc_obj_type_t type1, hwloc_obj_type_t type2)
{
  unsigned order1 = obj_type_order[type1];
  unsigned order2 = obj_type_order[type2];

  
  if (!hwloc__obj_type_is_normal(type1)
      && hwloc__obj_type_is_normal(type2) && type2 != HWLOC_OBJ_MACHINE)
    return HWLOC_TYPE_UNORDERED;
  if (!hwloc__obj_type_is_normal(type2)
      && hwloc__obj_type_is_normal(type1) && type1 != HWLOC_OBJ_MACHINE)
    return HWLOC_TYPE_UNORDERED;

  return order1 - order2;
}

enum hwloc_obj_cmp_e {
  HWLOC_OBJ_EQUAL = HWLOC_BITMAP_EQUAL,			
  HWLOC_OBJ_INCLUDED = HWLOC_BITMAP_INCLUDED,		
  HWLOC_OBJ_CONTAINS = HWLOC_BITMAP_CONTAINS,		
  HWLOC_OBJ_INTERSECTS = HWLOC_BITMAP_INTERSECTS,	
  HWLOC_OBJ_DIFFERENT = HWLOC_BITMAP_DIFFERENT		
};

static enum hwloc_obj_cmp_e
hwloc_type_cmp(hwloc_obj_t obj1, hwloc_obj_t obj2)
{
  hwloc_obj_type_t type1 = obj1->type;
  hwloc_obj_type_t type2 = obj2->type;
  int compare;

  compare = hwloc_compare_types(type1, type2);
  if (compare == HWLOC_TYPE_UNORDERED)
    return HWLOC_OBJ_DIFFERENT; 
  if (compare > 0)
    return HWLOC_OBJ_INCLUDED;
  if (compare < 0)
    return HWLOC_OBJ_CONTAINS;

  if (obj1->type == HWLOC_OBJ_GROUP
      && (obj1->attr->group.kind != obj2->attr->group.kind
	  || obj1->attr->group.subkind != obj2->attr->group.subkind))
    return HWLOC_OBJ_DIFFERENT; 

  return HWLOC_OBJ_EQUAL;
}


static int
hwloc_obj_cmp_sets(hwloc_obj_t obj1, hwloc_obj_t obj2)
{
  hwloc_bitmap_t set1, set2;

  assert(!hwloc__obj_type_is_special(obj1->type));
  assert(!hwloc__obj_type_is_special(obj2->type));

  
  if (obj1->complete_cpuset && obj2->complete_cpuset) {
    set1 = obj1->complete_cpuset;
    set2 = obj2->complete_cpuset;
  } else {
    set1 = obj1->cpuset;
    set2 = obj2->cpuset;
  }
  if (set1 && set2 && !hwloc_bitmap_iszero(set1) && !hwloc_bitmap_iszero(set2))
    return hwloc_bitmap_compare_inclusion(set1, set2);

  return HWLOC_OBJ_DIFFERENT;
}


int
hwloc__object_cpusets_compare_first(hwloc_obj_t obj1, hwloc_obj_t obj2)
{
  if (obj1->complete_cpuset && obj2->complete_cpuset)
    return hwloc_bitmap_compare_first(obj1->complete_cpuset, obj2->complete_cpuset);
  else if (obj1->cpuset && obj2->cpuset)
    return hwloc_bitmap_compare_first(obj1->cpuset, obj2->cpuset);
  return 0;
}




static void
merge_insert_equal(hwloc_obj_t new, hwloc_obj_t old)
{
  if (old->os_index == HWLOC_UNKNOWN_INDEX)
    old->os_index = new->os_index;

  if (new->infos_count) {
    
    hwloc__move_infos(&old->infos, &old->infos_count,
		      &new->infos, &new->infos_count);
  }

  if (new->name && !old->name) {
    old->name = new->name;
    new->name = NULL;
  }
  if (new->subtype && !old->subtype) {
    old->subtype = new->subtype;
    new->subtype = NULL;
  }

  

  switch(new->type) {
  case HWLOC_OBJ_NUMANODE:
    if (new->attr->numanode.local_memory && !old->attr->numanode.local_memory) {
      
      old->attr->numanode.local_memory = new->attr->numanode.local_memory;
      free(old->attr->numanode.page_types);
      old->attr->numanode.page_types_len = new->attr->numanode.page_types_len;
      old->attr->numanode.page_types = new->attr->numanode.page_types;
      new->attr->numanode.page_types = NULL;
      new->attr->numanode.page_types_len = 0;
    }
    
    break;
  case HWLOC_OBJ_L1CACHE:
  case HWLOC_OBJ_L2CACHE:
  case HWLOC_OBJ_L3CACHE:
  case HWLOC_OBJ_L4CACHE:
  case HWLOC_OBJ_L5CACHE:
  case HWLOC_OBJ_L1ICACHE:
  case HWLOC_OBJ_L2ICACHE:
  case HWLOC_OBJ_L3ICACHE:
    if (!old->attr->cache.size)
      old->attr->cache.size = new->attr->cache.size;
    if (!old->attr->cache.linesize)
      old->attr->cache.size = new->attr->cache.linesize;
    if (!old->attr->cache.associativity)
      old->attr->cache.size = new->attr->cache.linesize;
    break;
  default:
    break;
  }
}


static __hwloc_inline hwloc_obj_t
hwloc__insert_try_merge_group(hwloc_topology_t topology, hwloc_obj_t old, hwloc_obj_t new)
{
  if (new->type == HWLOC_OBJ_GROUP && old->type == HWLOC_OBJ_GROUP) {
    
    if (new->attr->group.dont_merge) {
      if (old->attr->group.dont_merge)
	
	return NULL;

      
      hwloc_replace_linked_object(old, new);
      topology->modified = 1;
      return new;

    } else {
      if (old->attr->group.dont_merge)
	
	return old;

      
      if (new->attr->group.kind < old->attr->group.kind) {
        
	hwloc_replace_linked_object(old, new);
        topology->modified = 1;
      }
      return old;
    }
  }

  if (new->type == HWLOC_OBJ_GROUP && !new->attr->group.dont_merge) {

    if (old->type == HWLOC_OBJ_PU && new->attr->group.kind == HWLOC_GROUP_KIND_MEMORY)
      
      return NULL;

    
    return old;

  } else if (old->type == HWLOC_OBJ_GROUP && !old->attr->group.dont_merge) {

    if (new->type == HWLOC_OBJ_PU && old->attr->group.kind == HWLOC_GROUP_KIND_MEMORY)
      
      return NULL;

    
    hwloc_replace_linked_object(old, new);
    topology->modified = 1;
    return old;

  } else {
    
    return NULL;
  }
}


static struct hwloc_obj *
hwloc___insert_object_by_cpuset(struct hwloc_topology *topology, hwloc_obj_t cur, hwloc_obj_t obj,
			        const char *reason)
{
  hwloc_obj_t child, next_child = NULL, tmp;
  
  hwloc_obj_t *cur_children = &cur->first_child;
  hwloc_obj_t *obj_children = &obj->first_child;
  
  hwloc_obj_t *putp = NULL; 

  assert(!hwloc__obj_type_is_memory(obj->type));

  
  for (child = cur->first_child, child ? next_child = child->next_sibling : NULL;
       child;
       child = next_child, child ? next_child = child->next_sibling : NULL) {

    int res = hwloc_obj_cmp_sets(obj, child);
    int setres = res;

    if (res == HWLOC_OBJ_EQUAL) {
      hwloc_obj_t merged = hwloc__insert_try_merge_group(topology, child, obj);
      if (merged)
	return merged;
      
      res = hwloc_type_cmp(obj, child);
    }

    switch (res) {
      case HWLOC_OBJ_EQUAL:
	
	merge_insert_equal(obj, child);
	
	return child;

      case HWLOC_OBJ_INCLUDED:
	
	return hwloc___insert_object_by_cpuset(topology, child, obj, reason);

      case HWLOC_OBJ_INTERSECTS:
        report_insert_error(obj, child, "intersection without inclusion", reason);
	goto putback;

      case HWLOC_OBJ_DIFFERENT:
        
	if (!putp && hwloc__object_cpusets_compare_first(obj, child) < 0)
	  
	  putp = cur_children;
	
	cur_children = &child->next_sibling;
	break;

      case HWLOC_OBJ_CONTAINS:
	
	*cur_children = child->next_sibling;
	child->next_sibling = NULL;
	
	*obj_children = child;
	obj_children = &child->next_sibling;
	child->parent = obj;
	if (setres == HWLOC_OBJ_EQUAL) {
	  obj->memory_first_child = child->memory_first_child;
	  child->memory_first_child = NULL;
	  for(tmp=obj->memory_first_child; tmp; tmp = tmp->next_sibling)
	    tmp->parent = obj;
	}
	break;
    }
  }
  
  assert(!*obj_children);
  assert(!*cur_children);

  
  if (!putp)
    putp = cur_children;
  obj->next_sibling = *putp;
  *putp = obj;
  obj->parent = cur;

  topology->modified = 1;
  return obj;

 putback:
  
  if (putp)
    cur_children = putp; 
  else
    cur_children = &cur->first_child; 
  
  while ((child = obj->first_child) != NULL) {
    
    obj->first_child = child->next_sibling;
    
    while (*cur_children && hwloc__object_cpusets_compare_first(*cur_children, child) < 0)
      cur_children = &(*cur_children)->next_sibling;
    child->next_sibling = *cur_children;
    *cur_children = child;
    child->parent = cur;
  }
  return NULL;
}


static struct hwloc_obj *
hwloc__find_obj_covering_memory_cpuset(struct hwloc_topology *topology, hwloc_obj_t parent, hwloc_bitmap_t cpuset)
{
  hwloc_obj_t child = hwloc_get_child_covering_cpuset(topology, cpuset, parent);
  if (!child)
    return parent;
  if (child && hwloc_bitmap_isequal(child->cpuset, cpuset))
    return child;
  return hwloc__find_obj_covering_memory_cpuset(topology, child, cpuset);
}

static struct hwloc_obj *
hwloc__find_insert_memory_parent(struct hwloc_topology *topology, hwloc_obj_t obj,
                                 const char *reason)
{
  hwloc_obj_t parent, group, result;

  if (hwloc_bitmap_iszero(obj->cpuset)) {
    
    parent = topology->levels[0][0];

  } else {
    
    parent = hwloc__find_obj_covering_memory_cpuset(topology, topology->levels[0][0], obj->cpuset);
    if (!parent) {
      
      parent = hwloc_get_root_obj(topology);
    }

    if (parent->type == HWLOC_OBJ_PU) {
      
      parent = parent->parent;
      assert(parent);
    }

    
    if (parent != topology->levels[0][0] && hwloc_bitmap_isequal(parent->cpuset, obj->cpuset))
      
      return parent;
  }

  if (!hwloc_filter_check_keep_object_type(topology, HWLOC_OBJ_GROUP))
    
    return parent;

  
  group = hwloc_alloc_setup_object(topology, HWLOC_OBJ_GROUP, HWLOC_UNKNOWN_INDEX);
  if (!group)
    
    return parent;

  group->attr->group.kind = HWLOC_GROUP_KIND_MEMORY;
  group->cpuset = hwloc_bitmap_dup(obj->cpuset);
  group->complete_cpuset = hwloc_bitmap_dup(obj->complete_cpuset);
  
  if (!group->cpuset != !obj->cpuset
      || !group->complete_cpuset != !obj->complete_cpuset) {
    
    hwloc_free_unlinked_object(group);
    return parent;
  }

  result = hwloc__insert_object_by_cpuset(topology, parent, group, reason);
  if (!result) {
    
    return parent;
  }

  assert(result == group);
  return group;
}


static hwloc_obj_t
hwloc___attach_memory_object_by_nodeset(struct hwloc_topology *topology, hwloc_obj_t parent,
					hwloc_obj_t obj, const char *reason)
{
  hwloc_obj_t *curp = &parent->memory_first_child;
  unsigned first = hwloc_bitmap_first(obj->nodeset);

  while (*curp) {
    hwloc_obj_t cur = *curp;
    unsigned curfirst = hwloc_bitmap_first(cur->nodeset);

    if (first < curfirst) {
      
      obj->next_sibling = cur;
      *curp = obj;
      obj->memory_first_child = NULL;
      obj->parent = parent;
      topology->modified = 1;
      return obj;
    }

    if (first == curfirst) {
      
      if (obj->type == HWLOC_OBJ_NUMANODE) {
	if (cur->type == HWLOC_OBJ_NUMANODE) {
	  
          report_insert_error(obj, cur, "NUMAnodes with identical nodesets", reason);
	  return NULL;
	}
	assert(cur->type == HWLOC_OBJ_MEMCACHE);
	
	return hwloc___attach_memory_object_by_nodeset(topology, cur, obj, reason);

      } else {
	assert(obj->type == HWLOC_OBJ_MEMCACHE);
	if (cur->type == HWLOC_OBJ_MEMCACHE) {
	  if (cur->attr->cache.depth == obj->attr->cache.depth)
	    
	    return NULL;
	  if (cur->attr->cache.depth > obj->attr->cache.depth)
	    
	    return hwloc___attach_memory_object_by_nodeset(topology, cur, obj, reason);
	}
	
	obj->next_sibling = cur->next_sibling;
	cur->next_sibling = NULL;
	obj->memory_first_child = cur;
	cur->parent = obj;
	*curp = obj;
	obj->parent = parent;
	topology->modified = 1;
	return obj;
      }
    }

    curp = &cur->next_sibling;
  }

  
  obj->next_sibling = NULL;
  *curp = obj;
  obj->memory_first_child = NULL;
  obj->parent = parent;
  topology->modified = 1;
  return obj;
}


struct hwloc_obj *
hwloc__attach_memory_object(struct hwloc_topology *topology, hwloc_obj_t parent,
			    hwloc_obj_t obj, const char *reason)
{
  hwloc_obj_t result;

  assert(parent);
  assert(hwloc__obj_type_is_normal(parent->type));

  
  if (!obj->nodeset || hwloc_bitmap_iszero(obj->nodeset))
    return NULL;
  
  if (!obj->complete_nodeset) {
    obj->complete_nodeset = hwloc_bitmap_dup(obj->nodeset);
  } else if (!hwloc_bitmap_isincluded(obj->nodeset, obj->complete_nodeset)) {
    return NULL;
  }
  
  assert(hwloc_bitmap_weight(obj->nodeset) == 1);

#if 0
  
  
  hwloc_bitmap_copy(obj->cpuset, parent->cpuset);
  hwloc_bitmap_copy(obj->complete_cpuset, parent->complete_cpuset);
#endif

  result = hwloc___attach_memory_object_by_nodeset(topology, parent, obj, reason);
  if (result == obj) {
    
    if (obj->type == HWLOC_OBJ_NUMANODE) {
      hwloc_bitmap_set(topology->levels[0][0]->nodeset, obj->os_index);
      hwloc_bitmap_set(topology->levels[0][0]->complete_nodeset, obj->os_index);
    }
  }
  if (result != obj) {
    
    hwloc_free_unlinked_object(obj);
  }
  return result;
}


struct hwloc_obj *
hwloc__insert_object_by_cpuset(struct hwloc_topology *topology, hwloc_obj_t root,
			       hwloc_obj_t obj, const char *reason)
{
  struct hwloc_obj *result;

#ifdef HWLOC_DEBUG
  assert(!hwloc__obj_type_is_special(obj->type));

  
  assert(obj->cpuset || obj->complete_cpuset || obj->nodeset || obj->complete_nodeset);
  
#endif

  if (hwloc__obj_type_is_memory(obj->type)) {
    if (!root) {
      root = hwloc__find_insert_memory_parent(topology, obj, reason);
      if (!root) {
	hwloc_free_unlinked_object(obj);
	return NULL;
      }
    }
    return hwloc__attach_memory_object(topology, root, obj, reason);
  }

  if (!root)
    
    root = topology->levels[0][0];

  result = hwloc___insert_object_by_cpuset(topology, root, obj, reason);
  if (result && result->type == HWLOC_OBJ_PU) {
      
      if (hwloc_bitmap_isset(result->cpuset, result->os_index))
	hwloc_bitmap_set(topology->levels[0][0]->cpuset, result->os_index);
      hwloc_bitmap_set(topology->levels[0][0]->complete_cpuset, result->os_index);
  }
  if (result != obj) {
    
    hwloc_free_unlinked_object(obj);
  }
  return result;
}


void
hwloc_insert_object_by_parent(struct hwloc_topology *topology, hwloc_obj_t parent, hwloc_obj_t obj)
{
  hwloc_obj_t *current;

  if (obj->type == HWLOC_OBJ_MISC) {
    
    for (current = &parent->misc_first_child; *current; current = &(*current)->next_sibling);
  } else if (hwloc__obj_type_is_io(obj->type)) {
    
    for (current = &parent->io_first_child; *current; current = &(*current)->next_sibling);
  } else if (hwloc__obj_type_is_memory(obj->type)) {
    
    for (current = &parent->memory_first_child; *current; current = &(*current)->next_sibling);
    
    if (obj->type == HWLOC_OBJ_NUMANODE) {
      if (hwloc_bitmap_isset(obj->nodeset, obj->os_index))
	hwloc_bitmap_set(topology->levels[0][0]->nodeset, obj->os_index);
      hwloc_bitmap_set(topology->levels[0][0]->complete_nodeset, obj->os_index);
    }
  } else {
    
    for (current = &parent->first_child; *current; current = &(*current)->next_sibling);
    
    if (obj->type == HWLOC_OBJ_PU) {
      if (hwloc_bitmap_isset(obj->cpuset, obj->os_index))
	hwloc_bitmap_set(topology->levels[0][0]->cpuset, obj->os_index);
      hwloc_bitmap_set(topology->levels[0][0]->complete_cpuset, obj->os_index);
    }
  }

  *current = obj;
  obj->parent = parent;
  obj->next_sibling = NULL;
  topology->modified = 1;
}

hwloc_obj_t
hwloc_alloc_setup_object(hwloc_topology_t topology,
			 hwloc_obj_type_t type, unsigned os_index)
{
  struct hwloc_obj *obj = hwloc_tma_malloc(topology->tma, sizeof(*obj));
  if (!obj)
    return NULL;
  memset(obj, 0, sizeof(*obj));
  obj->type = type;
  obj->os_index = os_index;
  obj->gp_index = topology->next_gp_index++;
  obj->attr = hwloc_tma_malloc(topology->tma, sizeof(*obj->attr));
  if (!obj->attr) {
    assert(!topology->tma || !topology->tma->dontfree); 
    free(obj);
    return NULL;
  }
  memset(obj->attr, 0, sizeof(*obj->attr));
  
  return obj;
}

hwloc_obj_t
hwloc_topology_alloc_group_object(struct hwloc_topology *topology)
{
  if (!topology->is_loaded) {
    
    errno = EINVAL;
    return NULL;
  }
  if (topology->adopted_shmem_addr) {
    errno = EPERM;
    return NULL;
  }
  return hwloc_alloc_setup_object(topology, HWLOC_OBJ_GROUP, HWLOC_UNKNOWN_INDEX);
}

int
hwloc_topology_free_group_object(struct hwloc_topology *topology, hwloc_obj_t obj)
{
  if (!topology->is_loaded) {
    
    errno = EINVAL;
    return -1;
  }
  if (topology->adopted_shmem_addr) {
    errno = EPERM;
    return -1;
  }
  hwloc_free_unlinked_object(obj);
  return 0;
}

static void hwloc_propagate_symmetric_subtree(hwloc_topology_t topology, hwloc_obj_t root);
static void propagate_total_memory(hwloc_obj_t obj);
static void hwloc_set_group_depth(hwloc_topology_t topology);
static void hwloc_connect_children(hwloc_obj_t parent);
static int hwloc_connect_levels(hwloc_topology_t topology);
static int hwloc_connect_special_levels(hwloc_topology_t topology);

hwloc_obj_t
hwloc_topology_insert_group_object(struct hwloc_topology *topology, hwloc_obj_t obj)
{
  hwloc_obj_t res, root, child;
  int cmp;

  if (!topology->is_loaded) {
    
    hwloc_free_unlinked_object(obj);
    errno = EINVAL;
    return NULL;
  }
  if (topology->adopted_shmem_addr) {
    hwloc_free_unlinked_object(obj);
    errno = EPERM;
    return NULL;
  }

  if (topology->type_filter[HWLOC_OBJ_GROUP] == HWLOC_TYPE_FILTER_KEEP_NONE) {
    hwloc_free_unlinked_object(obj);
    errno = EINVAL;
    return NULL;
  }

  root = hwloc_get_root_obj(topology);
  if (obj->cpuset)
    hwloc_bitmap_and(obj->cpuset, obj->cpuset, root->cpuset);
  if (obj->complete_cpuset)
    hwloc_bitmap_and(obj->complete_cpuset, obj->complete_cpuset, root->complete_cpuset);
  if (obj->nodeset)
    hwloc_bitmap_and(obj->nodeset, obj->nodeset, root->nodeset);
  if (obj->complete_nodeset)
    hwloc_bitmap_and(obj->complete_nodeset, obj->complete_nodeset, root->complete_nodeset);

  if ((!obj->cpuset || hwloc_bitmap_iszero(obj->cpuset))
      && (!obj->complete_cpuset || hwloc_bitmap_iszero(obj->complete_cpuset))) {
    
    hwloc_const_bitmap_t nodeset = obj->nodeset ? obj->nodeset : obj->complete_nodeset;
    hwloc_obj_t numa;

    if ((!obj->nodeset || hwloc_bitmap_iszero(obj->nodeset))
	&& (!obj->complete_nodeset || hwloc_bitmap_iszero(obj->complete_nodeset))) {
      hwloc_free_unlinked_object(obj);
      errno = EINVAL;
      return NULL;
    }

    if (!obj->cpuset) {
      obj->cpuset = hwloc_bitmap_alloc();
      if (!obj->cpuset) {
	hwloc_free_unlinked_object(obj);
	return NULL;
      }
    }

    numa = NULL;
    while ((numa = hwloc_get_next_obj_by_type(topology, HWLOC_OBJ_NUMANODE, numa)) != NULL)
      if (hwloc_bitmap_isset(nodeset, numa->os_index))
	hwloc_bitmap_or(obj->cpuset, obj->cpuset, numa->cpuset);
  }
  

  cmp = hwloc_obj_cmp_sets(obj, root);
  if (cmp == HWLOC_OBJ_INCLUDED) {
    res = hwloc__insert_object_by_cpuset(topology, NULL, obj, NULL );
  } else {
    
    hwloc_free_unlinked_object(obj);
    res = root;
  }

  if (!res)
    return NULL;

  if (res != obj && res->type != HWLOC_OBJ_GROUP)
    
    return res;

  

  
  hwloc_obj_add_children_sets(res);
  if (hwloc_topology_reconnect(topology, 0) < 0)
    return NULL;

  
  res->total_memory = 0;
  for_each_child(child, res)
    res->total_memory += child->total_memory;
  for_each_memory_child(child, res)
    res->total_memory += child->total_memory;

  hwloc_propagate_symmetric_subtree(topology, topology->levels[0][0]);
  hwloc_set_group_depth(topology);

#ifndef HWLOC_DEBUG
  if (getenv("HWLOC_DEBUG_CHECK"))
#endif
    hwloc_topology_check(topology);

  return res;
}

hwloc_obj_t
hwloc_topology_insert_misc_object(struct hwloc_topology *topology, hwloc_obj_t parent, const char *name)
{
  hwloc_obj_t obj;

  if (topology->type_filter[HWLOC_OBJ_MISC] == HWLOC_TYPE_FILTER_KEEP_NONE) {
    errno = EINVAL;
    return NULL;
  }

  if (!topology->is_loaded) {
    errno = EINVAL;
    return NULL;
  }
  if (topology->adopted_shmem_addr) {
    errno = EPERM;
    return NULL;
  }

  obj = hwloc_alloc_setup_object(topology, HWLOC_OBJ_MISC, HWLOC_UNKNOWN_INDEX);
  if (name)
    obj->name = strdup(name);

  hwloc_insert_object_by_parent(topology, parent, obj);

  
  hwloc_topology_reconnect(topology, 0);

#ifndef HWLOC_DEBUG
  if (getenv("HWLOC_DEBUG_CHECK"))
#endif
    hwloc_topology_check(topology);

  return obj;
}


static hwloc_obj_t
hwloc_get_highest_obj_covering_complete_cpuset (hwloc_topology_t topology, hwloc_const_cpuset_t set)
{
  hwloc_obj_t current = hwloc_get_root_obj(topology);
  hwloc_obj_t child;

  if (hwloc_bitmap_isequal(set, current->complete_cpuset))
    
    return current;

 recurse:
  
  for_each_child(child, current) {
    if (hwloc_bitmap_isequal(set, child->complete_cpuset))
      
      return child;
    if (!hwloc_bitmap_iszero(child->complete_cpuset) && hwloc_bitmap_isincluded(set, child->complete_cpuset))
      break;
  }

  if (child) {
    current = child;
    goto recurse;
  }

  
  return current;
}

hwloc_obj_t
hwloc_find_insert_io_parent_by_complete_cpuset(struct hwloc_topology *topology, hwloc_cpuset_t cpuset)
{
  hwloc_obj_t group_obj, largeparent, parent;

  
  hwloc_bitmap_and(cpuset, cpuset, hwloc_topology_get_complete_cpuset(topology));
  if (hwloc_bitmap_iszero(cpuset))
    
    return NULL;

  largeparent = hwloc_get_highest_obj_covering_complete_cpuset(topology, cpuset);
  if (hwloc_bitmap_isequal(largeparent->complete_cpuset, cpuset)
      || !hwloc_filter_check_keep_object_type(topology, HWLOC_OBJ_GROUP))
    
    return largeparent;

  
  group_obj = hwloc_alloc_setup_object(topology, HWLOC_OBJ_GROUP, HWLOC_UNKNOWN_INDEX);
  if (!group_obj)
    
    return largeparent;

  group_obj->complete_cpuset = hwloc_bitmap_dup(cpuset);
  hwloc_bitmap_and(cpuset, cpuset, hwloc_topology_get_topology_cpuset(topology));
  group_obj->cpuset = hwloc_bitmap_dup(cpuset);
  group_obj->attr->group.kind = HWLOC_GROUP_KIND_IO;
  parent = hwloc__insert_object_by_cpuset(topology, largeparent, group_obj, "topology:io_parent");
  if (!parent)
    
    return largeparent;

  
  assert(parent == group_obj);

  
  hwloc_obj_add_children_sets(group_obj);

  return parent;
}

static int hwloc_memory_page_type_compare(const void *_a, const void *_b)
{
  const struct hwloc_memory_page_type_s *a = _a;
  const struct hwloc_memory_page_type_s *b = _b;
  
  if (!b->size)
    return -1;
  
  if (b->size == a->size)
    return 0;
  return a->size < b->size ? -1 : 1;
}


static void
propagate_total_memory(hwloc_obj_t obj)
{
  hwloc_obj_t child;
  unsigned i;

  
  obj->total_memory = 0;

  
  for_each_child(child, obj) {
    propagate_total_memory(child);
    obj->total_memory += child->total_memory;
  }
  for_each_memory_child(child, obj) {
    propagate_total_memory(child);
    obj->total_memory += child->total_memory;
  }
  

  if (obj->type == HWLOC_OBJ_NUMANODE) {
    obj->total_memory += obj->attr->numanode.local_memory;

    if (obj->attr->numanode.page_types_len) {
      
      qsort(obj->attr->numanode.page_types, obj->attr->numanode.page_types_len, sizeof(*obj->attr->numanode.page_types), hwloc_memory_page_type_compare);
      
      for(i=obj->attr->numanode.page_types_len; i>=1; i--)
	if (obj->attr->numanode.page_types[i-1].size)
	  break;
      obj->attr->numanode.page_types_len = i;
    }
  }
}


static void
fixup_sets(hwloc_obj_t obj)
{
  int in_memory_list;
  hwloc_obj_t child;

  child = obj->first_child;
  in_memory_list = 0;
  

  
 iterate:
  while (child) {
    
    hwloc_bitmap_and(child->cpuset, child->cpuset, obj->cpuset);
    hwloc_bitmap_and(child->nodeset, child->nodeset, obj->nodeset);
    
    if (child->complete_cpuset) {
      hwloc_bitmap_and(child->complete_cpuset, child->complete_cpuset, obj->complete_cpuset);
    } else {
      child->complete_cpuset = hwloc_bitmap_dup(child->cpuset);
    }
    if (child->complete_nodeset) {
      hwloc_bitmap_and(child->complete_nodeset, child->complete_nodeset, obj->complete_nodeset);
    } else {
      child->complete_nodeset = hwloc_bitmap_dup(child->nodeset);
    }

    if (hwloc_obj_type_is_memory(child->type)) {
      
      hwloc_bitmap_copy(child->cpuset, obj->cpuset);
      hwloc_bitmap_copy(child->complete_cpuset, obj->complete_cpuset);
    }

    fixup_sets(child);
    child = child->next_sibling;
  }

  
  if (!in_memory_list && obj->memory_first_child) {
    child = obj->memory_first_child;
    in_memory_list = 1;
    goto iterate;
  }

  
}


int
hwloc_obj_add_other_obj_sets(hwloc_obj_t dst, hwloc_obj_t src)
{
#define ADD_OTHER_OBJ_SET(_dst, _src, _set)					\
  if ((_src)->_set) {								\
    if (!(_dst)->_set)								\
      (_dst)->_set = hwloc_bitmap_alloc();					\
    if (!(_dst)->_set								\
        || hwloc_bitmap_or((_dst)->_set, (_dst)->_set, (_src)->_set) < 0)	\
      return -1;								\
  }
  ADD_OTHER_OBJ_SET(dst, src, cpuset);
  ADD_OTHER_OBJ_SET(dst, src, complete_cpuset);
  ADD_OTHER_OBJ_SET(dst, src, nodeset);
  ADD_OTHER_OBJ_SET(dst, src, complete_nodeset);
  return 0;
}

int
hwloc_obj_add_children_sets(hwloc_obj_t obj)
{
  hwloc_obj_t child;
  for_each_child(child, obj) {
    hwloc_obj_add_other_obj_sets(obj, child);
  }
  
  return 0;
}


static void
propagate_nodeset(hwloc_obj_t obj)
{
  hwloc_obj_t child;

  
  if (!obj->nodeset)
    obj->nodeset = hwloc_bitmap_alloc();
  if (obj->parent)
    hwloc_bitmap_copy(obj->nodeset, obj->parent->nodeset);
  else
    hwloc_bitmap_zero(obj->nodeset);

  
  if (!obj->complete_nodeset)
    obj->complete_nodeset = hwloc_bitmap_dup(obj->nodeset);
  else
    hwloc_bitmap_or(obj->complete_nodeset, obj->complete_nodeset, obj->nodeset);

  
  for_each_memory_child(child, obj) {
    
    hwloc_bitmap_or(obj->nodeset, obj->nodeset, child->nodeset);
    hwloc_bitmap_or(obj->complete_nodeset, obj->complete_nodeset, child->complete_nodeset);
    
  }

  
  for_each_child(child, obj) {
    propagate_nodeset(child);
  }

  
  for_each_child(child, obj) {
    hwloc_bitmap_or(obj->nodeset, obj->nodeset, child->nodeset);
    hwloc_bitmap_or(obj->complete_nodeset, obj->complete_nodeset, child->complete_nodeset);
  }

  

}

static void
remove_unused_sets(hwloc_topology_t topology, hwloc_obj_t obj)
{
  hwloc_obj_t child;

  hwloc_bitmap_and(obj->cpuset, obj->cpuset, topology->allowed_cpuset);
  hwloc_bitmap_and(obj->nodeset, obj->nodeset, topology->allowed_nodeset);

  for_each_child(child, obj)
    remove_unused_sets(topology, child);
  for_each_memory_child(child, obj)
    remove_unused_sets(topology, child);
  
}

static void
hwloc__filter_bridges(hwloc_topology_t topology, hwloc_obj_t root, unsigned depth)
{
  hwloc_obj_t child, *pchild;

  
  for_each_io_child_safe(child, root, pchild) {
    enum hwloc_type_filter_e filter = topology->type_filter[child->type];

    
    hwloc__filter_bridges(topology, child, depth+1);

    child->attr->bridge.depth = depth;

    
    if (filter == HWLOC_TYPE_FILTER_KEEP_IMPORTANT
	&& !child->io_first_child
        && (child->type == HWLOC_OBJ_BRIDGE
            || (child->type == HWLOC_OBJ_PCI_DEVICE && (child->attr->pcidev.class_id >> 8) == 0x06
                && (!child->subtype || strcmp(child->subtype, "NVSwitch"))))) {
      unlink_and_free_single_object(pchild);
      topology->modified = 1;
    }
  }
}

static void
hwloc_filter_bridges(hwloc_topology_t topology, hwloc_obj_t parent)
{
  hwloc_obj_t child = parent->first_child;
  while (child) {
    hwloc_filter_bridges(topology, child);
    child = child->next_sibling;
  }

  hwloc__filter_bridges(topology, parent, 0);
}

void
hwloc__reorder_children(hwloc_obj_t parent)
{
  
  hwloc_obj_t *prev, child, children = parent->first_child;
  parent->first_child = NULL;
  while (children) {
    
    child = children;
    children = child->next_sibling;
    
    prev = &parent->first_child;
    while (*prev && hwloc__object_cpusets_compare_first(child, *prev) > 0)
      prev = &((*prev)->next_sibling);
    
    child->next_sibling = *prev;
    *prev = child;
  }
  
}


static void
remove_empty(hwloc_topology_t topology, hwloc_obj_t *pobj)
{
  hwloc_obj_t obj = *pobj, child, *pchild;

  for_each_child_safe(child, obj, pchild)
    remove_empty(topology, pchild);
  for_each_memory_child_safe(child, obj, pchild)
    remove_empty(topology, pchild);
  

  if (obj->first_child 
      || obj->memory_first_child 
      || obj->io_first_child )
    
    return;

  if (hwloc__obj_type_is_normal(obj->type)) {
    if (!hwloc_bitmap_iszero(obj->cpuset))
      return;
  } else {
    assert(hwloc__obj_type_is_memory(obj->type));
    if (!hwloc_bitmap_iszero(obj->nodeset))
      return;
  }

  hwloc_debug("%s", "\nRemoving empty object ");
  hwloc_debug_print_object(0, obj);
  unlink_and_free_single_object(pobj);
  topology->modified = 1;
}


static void
hwloc_reset_normal_type_depths(hwloc_topology_t topology)
{
  unsigned i;
  for (i=HWLOC_OBJ_TYPE_MIN; i<=HWLOC_OBJ_GROUP; i++)
    topology->type_depth[i] = HWLOC_TYPE_DEPTH_UNKNOWN;
  
  topology->type_depth[HWLOC_OBJ_DIE] = HWLOC_TYPE_DEPTH_UNKNOWN;
}

static int
hwloc_dont_merge_group_level(hwloc_topology_t topology, unsigned i)
{
  unsigned j;

  
  for(j=0; j<topology->level_nbobjects[i]; j++)
    if (topology->levels[i][j]->attr->group.dont_merge)
      return 1;

  return 0;
}


static int
hwloc_compare_levels_structure(hwloc_topology_t topology, unsigned i)
{
  int checkmemory = (topology->levels[i][0]->type == HWLOC_OBJ_PU);
  unsigned j;

  if (topology->level_nbobjects[i-1] != topology->level_nbobjects[i])
    return -1;

  for(j=0; j<topology->level_nbobjects[i]; j++) {
    if (topology->levels[i-1][j] != topology->levels[i][j]->parent)
      return -1;
    if (topology->levels[i-1][j]->arity != 1)
      return -1;
    if (checkmemory && topology->levels[i-1][j]->memory_arity)
      
      return -1;
  }
  
  return 0;
}


static int
hwloc_filter_levels_keep_structure(hwloc_topology_t topology)
{
  unsigned i, j;
  int res = 0;

  if (topology->modified) {
    
    hwloc_connect_children(topology->levels[0][0]);
    if (hwloc_connect_levels(topology) < 0)
      return -1;
  }

  
  for(i=topology->nb_levels-1; i>0; i--) {
    int replacechild = 0, replaceparent = 0;
    hwloc_obj_t obj1 = topology->levels[i-1][0];
    hwloc_obj_t obj2 = topology->levels[i][0];
    hwloc_obj_type_t type1 = obj1->type;
    hwloc_obj_type_t type2 = obj2->type;

    
    if (topology->type_filter[type1] == HWLOC_TYPE_FILTER_KEEP_STRUCTURE) {
      
      replaceparent = 1;
      if (type1 == HWLOC_OBJ_GROUP && hwloc_dont_merge_group_level(topology, i-1))
	replaceparent = 0;
    }
    if (topology->type_filter[type2] == HWLOC_TYPE_FILTER_KEEP_STRUCTURE) {
      
      replacechild = 1;
      if (type1 == HWLOC_OBJ_GROUP && hwloc_dont_merge_group_level(topology, i))
	replacechild = 0;
    }
    if (!replacechild && !replaceparent)
      
      continue;
    
    if (replaceparent && replacechild) {
      
      if (obj_type_priority[type1] >= obj_type_priority[type2])
	replaceparent = 0;
      else
	replacechild = 0;
    }
    
    if (hwloc_compare_levels_structure(topology, i) < 0)
      continue;
    hwloc_debug("may merge levels #%u=%s and #%u=%s\n",
		i-1, hwloc_obj_type_string(type1), i, hwloc_obj_type_string(type2));

    
    for(j=0; j<topology->level_nbobjects[i]; j++) {
      hwloc_obj_t parent = topology->levels[i-1][j];
      hwloc_obj_t child = topology->levels[i][j];
      unsigned k;
      if (replacechild) {
	
	parent->first_child = child->first_child;
	parent->last_child = child->last_child;
	parent->arity = child->arity;
	free(parent->children);
	parent->children = child->children;
	child->children = NULL;
	
	for(k=0; k<parent->arity; k++)
	  parent->children[k]->parent = parent;
	
	if (child->memory_first_child) {
	  append_siblings_list(&parent->memory_first_child, child->memory_first_child, parent);
	  parent->memory_arity += child->memory_arity;
	}
	if (child->io_first_child) {
	  append_siblings_list(&parent->io_first_child, child->io_first_child, parent);
	  parent->io_arity += child->io_arity;
	}
	if (child->misc_first_child) {
	  append_siblings_list(&parent->misc_first_child, child->misc_first_child, parent);
	  parent->misc_arity += child->misc_arity;
	}
	hwloc_free_unlinked_object(child);
      } else {
	
	if (parent->parent) {
	  parent->parent->children[parent->sibling_rank] = child;
	  child->sibling_rank = parent->sibling_rank;
	  if (!parent->sibling_rank) {
	    parent->parent->first_child = child;
	    
	  } else {
	    child->prev_sibling = parent->parent->children[parent->sibling_rank-1];
	    child->prev_sibling->next_sibling = child;
	  }
	  if (parent->sibling_rank == parent->parent->arity-1) {
	    parent->parent->last_child = child;
	    
	  } else {
	    child->next_sibling = parent->parent->children[parent->sibling_rank+1];
	    child->next_sibling->prev_sibling = child;
	  }
	  
	  child->parent = parent->parent;
	} else {
	  
	  topology->levels[0][0] = child;
	  child->parent = NULL;
	}
	
	if (parent->memory_first_child) {
	  prepend_siblings_list(&child->memory_first_child, parent->memory_first_child, child);
	  child->memory_arity += parent->memory_arity;
	}
	if (parent->io_first_child) {
	  prepend_siblings_list(&child->io_first_child, parent->io_first_child, child);
	  child->io_arity += parent->io_arity;
	}
	if (parent->misc_first_child) {
	  prepend_siblings_list(&child->misc_first_child, parent->misc_first_child, child);
	  child->misc_arity += parent->misc_arity;
	}
	hwloc_free_unlinked_object(parent);
	
      }
    }
    if (replaceparent && i>1) {
      
      for(j=0; j<topology->level_nbobjects[i]; j++) {
	hwloc_obj_t child = topology->levels[i][j];
	unsigned rank = child->sibling_rank;
	child->prev_sibling = rank > 0 ? child->parent->children[rank-1] : NULL;
	child->next_sibling = rank < child->parent->arity-1 ? child->parent->children[rank+1] : NULL;
      }
    }

    
    if (replaceparent) {
      
      free(topology->levels[i-1]);
      memmove(&topology->levels[i-1],
	      &topology->levels[i],
	      (topology->nb_levels-i)*sizeof(topology->levels[i]));
      memmove(&topology->level_nbobjects[i-1],
	      &topology->level_nbobjects[i],
	      (topology->nb_levels-i)*sizeof(topology->level_nbobjects[i]));
      hwloc_debug("removed parent level %s at depth %u\n",
		  hwloc_obj_type_string(type1), i-1);
    } else {
      
      free(topology->levels[i]);
      memmove(&topology->levels[i],
	      &topology->levels[i+1],
	      (topology->nb_levels-1-i)*sizeof(topology->levels[i]));
      memmove(&topology->level_nbobjects[i],
	      &topology->level_nbobjects[i+1],
	      (topology->nb_levels-1-i)*sizeof(topology->level_nbobjects[i]));
      hwloc_debug("removed child level %s at depth %u\n",
		  hwloc_obj_type_string(type2), i);
    }
    topology->level_nbobjects[topology->nb_levels-1] = 0;
    topology->levels[topology->nb_levels-1] = NULL;
    topology->nb_levels--;

    res++;
  }

  if (res > 0) {
    
    hwloc_reset_normal_type_depths(topology);
    for(i=0; i<topology->nb_levels; i++) {
      hwloc_obj_type_t type = topology->levels[i][0]->type;
      for(j=0; j<topology->level_nbobjects[i]; j++)
	topology->levels[i][j]->depth = (int)i;
      if (topology->type_depth[type] == HWLOC_TYPE_DEPTH_UNKNOWN)
	topology->type_depth[type] = (int)i;
      else
	topology->type_depth[type] = HWLOC_TYPE_DEPTH_MULTIPLE;
    }
  }


  if (res > 0 || topology-> modified) {
    
    if (hwloc_connect_special_levels(topology) < 0)
      return -1;
    topology->modified = 0;
  }

  return 0;
}

static void
hwloc_propagate_symmetric_subtree(hwloc_topology_t topology, hwloc_obj_t root)
{
  hwloc_obj_t child;
  unsigned arity = root->arity;
  hwloc_obj_t *array;
  int ok;

  
  root->symmetric_subtree = 0;

  
  if (!arity)
    goto good;

  

  
  ok = 1;
  for_each_child(child, root) {
    hwloc_propagate_symmetric_subtree(topology, child);
    if (!child->symmetric_subtree)
      ok = 0;
  }
  if (!ok)
    return;
  

  
  if (arity == 1)
    goto good;

  
  array = malloc(arity * sizeof(*array));
  if (!array)
    return;
  memcpy(array, root->children, arity * sizeof(*array));
  while (1) {
    unsigned i;
    
    for(i=1; i<arity; i++)
      if (array[i]->depth != array[0]->depth
	  || array[i]->arity != array[0]->arity) {
	free(array);
	return;
      }
    if (!array[0]->arity)
      
      break;
    
    for(i=0; i<arity; i++)
      array[i] = array[i]->first_child;
  }
  free(array);

  
 good:
  root->symmetric_subtree = 1;
}

static void hwloc_set_group_depth(hwloc_topology_t topology)
{
  unsigned groupdepth = 0;
  unsigned i, j;
  for(i=0; i<topology->nb_levels; i++)
    if (topology->levels[i][0]->type == HWLOC_OBJ_GROUP) {
      for (j = 0; j < topology->level_nbobjects[i]; j++)
	topology->levels[i][j]->attr->group.depth = groupdepth;
      groupdepth++;
    }
}


static void
hwloc_connect_children(hwloc_obj_t parent)
{
  unsigned n, oldn = parent->arity;
  hwloc_obj_t child, prev_child;
  int ok;

  

  ok = 1;
  prev_child = NULL;
  for (n = 0, child = parent->first_child;
       child;
       n++,   prev_child = child, child = child->next_sibling) {
    child->sibling_rank = n;
    child->prev_sibling = prev_child;
    
    if (n >= oldn || parent->children[n] != child)
      ok = 0;
    
    hwloc_connect_children(child);
  }
  parent->last_child = prev_child;
  parent->arity = n;
  if (!n) {
    
    free(parent->children);
    parent->children = NULL;
    goto memory;
  }
  if (ok)
    
    goto memory;

  
  if (oldn < n) {
    free(parent->children);
    parent->children = malloc(n * sizeof(*parent->children));
  }
  
  for (n = 0, child = parent->first_child;
       child;
       n++,   child = child->next_sibling) {
    parent->children[n] = child;
  }



 memory:
  

  prev_child = NULL;
  for (n = 0, child = parent->memory_first_child;
       child;
       n++,   prev_child = child, child = child->next_sibling) {
    child->parent = parent;
    child->sibling_rank = n;
    child->prev_sibling = prev_child;
    hwloc_connect_children(child);
  }
  parent->memory_arity = n;

  

  prev_child = NULL;
  for (n = 0, child = parent->io_first_child;
       child;
       n++,   prev_child = child, child = child->next_sibling) {
    child->parent = parent;
    child->sibling_rank = n;
    child->prev_sibling = prev_child;
    hwloc_connect_children(child);
  }
  parent->io_arity = n;

  

  prev_child = NULL;
  for (n = 0, child = parent->misc_first_child;
       child;
       n++,   prev_child = child, child = child->next_sibling) {
    child->parent = parent;
    child->sibling_rank = n;
    child->prev_sibling = prev_child;
    hwloc_connect_children(child);
  }
  parent->misc_arity = n;
}


static int
find_same_type(hwloc_obj_t root, hwloc_obj_t obj)
{
  hwloc_obj_t child;

  for_each_child (child, root) {
    if (hwloc_type_cmp(child, obj) == HWLOC_OBJ_EQUAL)
      return 1;
    if (find_same_type(child, obj))
      return 1;
  }

  return 0;
}

static int
hwloc_build_level_from_list(struct hwloc_special_level_s *slevel)
{
  unsigned i, nb;
  struct hwloc_obj * obj;

  
  obj = slevel->first;
  i = 0;
  while (obj) {
    i++;
    obj = obj->next_cousin;
  }
  nb = i;

  if (nb) {
    
    slevel->objs = malloc(nb * sizeof(struct hwloc_obj *));
    if (!slevel->objs)
      return -1;

    obj = slevel->first;
    i = 0;
    while (obj) {
      obj->logical_index = i;
      slevel->objs[i] = obj;
      i++;
      obj = obj->next_cousin;
    }
  }

  slevel->nbobjs = nb;
  return 0;
}

static void
hwloc_append_special_object(struct hwloc_special_level_s *level, hwloc_obj_t obj)
{
  if (level->first) {
    obj->prev_cousin = level->last;
    obj->prev_cousin->next_cousin = obj;
    level->last = obj;
  } else {
    obj->prev_cousin = NULL;
    level->first = level->last = obj;
  }
}


static void
hwloc_list_special_objects(hwloc_topology_t topology, hwloc_obj_t obj)
{
  hwloc_obj_t child;

  if (obj->type == HWLOC_OBJ_NUMANODE) {
    obj->next_cousin = NULL;
    obj->depth = HWLOC_TYPE_DEPTH_NUMANODE;
    
    hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_NUMANODE], obj);

    
    for_each_misc_child(child, obj)
      hwloc_list_special_objects(topology, child);

  } else if (obj->type == HWLOC_OBJ_MEMCACHE) {
    obj->next_cousin = NULL;
    obj->depth = HWLOC_TYPE_DEPTH_MEMCACHE;
    
    hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_MEMCACHE], obj);

    
    for_each_memory_child(child, obj)
      hwloc_list_special_objects(topology, child);
    for_each_misc_child(child, obj)
      hwloc_list_special_objects(topology, child);

  } else if (obj->type == HWLOC_OBJ_MISC) {
    obj->next_cousin = NULL;
    obj->depth = HWLOC_TYPE_DEPTH_MISC;
    
    hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_MISC], obj);
    
    for_each_misc_child(child, obj)
      hwloc_list_special_objects(topology, child);

  } else if (hwloc__obj_type_is_io(obj->type)) {
    obj->next_cousin = NULL;

    if (obj->type == HWLOC_OBJ_BRIDGE) {
      obj->depth = HWLOC_TYPE_DEPTH_BRIDGE;
      
      hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_BRIDGE], obj);

    } else if (obj->type == HWLOC_OBJ_PCI_DEVICE) {
      obj->depth = HWLOC_TYPE_DEPTH_PCI_DEVICE;
      
      hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_PCIDEV], obj);

    } else if (obj->type == HWLOC_OBJ_OS_DEVICE) {
      obj->depth = HWLOC_TYPE_DEPTH_OS_DEVICE;
      
      hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_OSDEV], obj);
    }

    
    for_each_io_child(child, obj)
      hwloc_list_special_objects(topology, child);
    for_each_misc_child(child, obj)
      hwloc_list_special_objects(topology, child);

  } else {
    
    for_each_child(child, obj)
      hwloc_list_special_objects(topology, child);
    for_each_memory_child(child, obj)
      hwloc_list_special_objects(topology, child);
    for_each_io_child(child, obj)
      hwloc_list_special_objects(topology, child);
    for_each_misc_child(child, obj)
      hwloc_list_special_objects(topology, child);
  }
}


static int
hwloc_connect_special_levels(hwloc_topology_t topology)
{
  unsigned i;

  for(i=0; i<HWLOC_NR_SLEVELS; i++)
    free(topology->slevels[i].objs);
  memset(&topology->slevels, 0, sizeof(topology->slevels));

  hwloc_list_special_objects(topology, topology->levels[0][0]);

  for(i=0; i<HWLOC_NR_SLEVELS; i++) {
    if (hwloc_build_level_from_list(&topology->slevels[i]) < 0)
      return -1;
  }

  return 0;
}


static int
hwloc_connect_levels(hwloc_topology_t topology)
{
  unsigned l, i=0;
  hwloc_obj_t *objs, *taken_objs, *new_objs, top_obj, root;
  unsigned n_objs, n_taken_objs, n_new_objs;

  
  for(l=1; l<topology->nb_levels; l++)
    free(topology->levels[l]);
  memset(topology->levels+1, 0, (topology->nb_levels-1)*sizeof(*topology->levels));
  memset(topology->level_nbobjects+1, 0, (topology->nb_levels-1)*sizeof(*topology->level_nbobjects));
  topology->nb_levels = 1;

  
  hwloc_reset_normal_type_depths(topology);

  
  root = topology->levels[0][0];
  root->depth = 0;
  topology->type_depth[root->type] = 0;
  
  root->logical_index = 0;
  root->prev_cousin = NULL;
  root->next_cousin = NULL;
  
  root->parent = NULL;
  root->sibling_rank = 0;
  root->prev_sibling = NULL;
  root->next_sibling = NULL;

  
  n_objs = topology->levels[0][0]->arity;
  objs = malloc(n_objs * sizeof(objs[0]));
  if (!objs) {
    errno = ENOMEM;
    return -1;
  }
  memcpy(objs, topology->levels[0][0]->children, n_objs*sizeof(objs[0]));

  
  while (n_objs) {
    

    

    
    for (i = 0; i < n_objs; i++)
      if (objs[i]->type != HWLOC_OBJ_PU)
        break;
    top_obj = i == n_objs ? objs[0] : objs[i];

    
    for (i = 0; i < n_objs; i++) {
      if (hwloc_type_cmp(top_obj, objs[i]) != HWLOC_OBJ_EQUAL) {
	if (find_same_type(objs[i], top_obj)) {
	  
	  top_obj = objs[i];
	}
      }
    }

    

    
    taken_objs = malloc((n_objs+1) * sizeof(taken_objs[0]));
    if (!taken_objs) {
      free(objs);
      errno = ENOMEM;
      return -1;
    }

    
    n_new_objs = 0;
    for (i = 0; i < n_objs; i++) {
      if (objs[i]->arity)
	n_new_objs += objs[i]->arity;
      else
	n_new_objs++;
    }
    new_objs = malloc(n_new_objs * sizeof(new_objs[0]));
    if (!new_objs) {
      free(objs);
      free(taken_objs);
      errno = ENOMEM;
      return -1;
    }

    
    n_new_objs = 0;
    n_taken_objs = 0;
    for (i = 0; i < n_objs; i++)
      if (hwloc_type_cmp(top_obj, objs[i]) == HWLOC_OBJ_EQUAL) {
	
	taken_objs[n_taken_objs++] = objs[i];
	if (objs[i]->arity)
	  memcpy(&new_objs[n_new_objs], objs[i]->children, objs[i]->arity * sizeof(new_objs[0]));
	n_new_objs += objs[i]->arity;
      } else {
	
	new_objs[n_new_objs++] = objs[i];
      }

    if (!n_new_objs) {
      free(new_objs);
      new_objs = NULL;
    }

    
    for (i = 0; i < n_taken_objs; i++) {
      taken_objs[i]->depth = (int) topology->nb_levels;
      taken_objs[i]->logical_index = i;
      if (i) {
	taken_objs[i]->prev_cousin = taken_objs[i-1];
	taken_objs[i-1]->next_cousin = taken_objs[i];
      }
    }
    taken_objs[0]->prev_cousin = NULL;
    taken_objs[n_taken_objs-1]->next_cousin = NULL;

    
    hwloc_debug("--- %s level", hwloc_obj_type_string(top_obj->type));
    hwloc_debug(" has number %u\n\n", topology->nb_levels);

    if (topology->type_depth[top_obj->type] == HWLOC_TYPE_DEPTH_UNKNOWN)
      topology->type_depth[top_obj->type] = (int) topology->nb_levels;
    else
      topology->type_depth[top_obj->type] = HWLOC_TYPE_DEPTH_MULTIPLE; 

    taken_objs[n_taken_objs] = NULL;

    if (topology->nb_levels == topology->nb_levels_allocated) {
      
      void *tmplevels, *tmpnbobjs;
      tmplevels = realloc(topology->levels,
			  2 * topology->nb_levels_allocated * sizeof(*topology->levels));
      tmpnbobjs = realloc(topology->level_nbobjects,
			  2 * topology->nb_levels_allocated * sizeof(*topology->level_nbobjects));
      if (!tmplevels || !tmpnbobjs) {
        if (HWLOC_SHOW_CRITICAL_ERRORS())
          fprintf(stderr, "hwloc: failed to realloc level arrays to %u\n", topology->nb_levels_allocated * 2);

	
	if (tmplevels)
	  topology->levels = tmplevels;
	if (tmpnbobjs)
	  topology->level_nbobjects = tmpnbobjs;
	

	free(objs);
	free(taken_objs);
	free(new_objs);
	errno = ENOMEM;
	return -1;
      }
      topology->levels = tmplevels;
      topology->level_nbobjects = tmpnbobjs;
      memset(topology->levels + topology->nb_levels_allocated,
	     0, topology->nb_levels_allocated * sizeof(*topology->levels));
      memset(topology->level_nbobjects + topology->nb_levels_allocated,
	     0, topology->nb_levels_allocated * sizeof(*topology->level_nbobjects));
      topology->nb_levels_allocated *= 2;
    }
    
    topology->level_nbobjects[topology->nb_levels] = n_taken_objs;
    topology->levels[topology->nb_levels] = taken_objs;

    topology->nb_levels++;

    free(objs);

    
    objs = new_objs;
    n_objs = n_new_objs;
  }

  
  free(objs);

  return 0;
}

int
hwloc_topology_reconnect(struct hwloc_topology *topology, unsigned long flags)
{
  

  if (flags) {
    errno = EINVAL;
    return -1;
  }
  if (!topology->modified)
    return 0;

  hwloc_connect_children(topology->levels[0][0]);

  if (hwloc_connect_levels(topology) < 0)
    return -1;

  if (hwloc_connect_special_levels(topology) < 0)
    return -1;

  topology->modified = 0;

  return 0;
}


static hwloc_obj_t
hwloc_debug_insert_osdev_sorted(hwloc_obj_t queue, hwloc_obj_t obj)
{
  hwloc_obj_t *pcur = &queue;
  while (*pcur && strcmp((*pcur)->name, obj->name) < 0)
    pcur = &((*pcur)->next_sibling);
  obj->next_sibling = *pcur;
  *pcur = obj;
  return queue;
}

static void
hwloc_debug_sort_children(hwloc_obj_t root)
{
  hwloc_obj_t child;

  if (root->io_first_child) {
    hwloc_obj_t osdevqueue, *pchild;

    pchild = &root->io_first_child;
    osdevqueue = NULL;
    while ((child = *pchild) != NULL) {
      if (child->type != HWLOC_OBJ_OS_DEVICE) {
	
	pchild = &child->next_sibling;
	continue;
      }

      
      *pchild = child->next_sibling;
      child->next_sibling = NULL;

      
      osdevqueue = hwloc_debug_insert_osdev_sorted(osdevqueue, child);
    }

    
    *pchild = osdevqueue;
  }

  
  for_each_child(child, root)
    hwloc_debug_sort_children(child);
  for_each_memory_child(child, root)
    hwloc_debug_sort_children(child);
  for_each_io_child(child, root)
    hwloc_debug_sort_children(child);
  
}

void hwloc_alloc_root_sets(hwloc_obj_t root)
{
  
  if (!root->cpuset)
     root->cpuset = hwloc_bitmap_alloc();
  if (!root->complete_cpuset)
     root->complete_cpuset = hwloc_bitmap_alloc();
  if (!root->nodeset)
    root->nodeset = hwloc_bitmap_alloc();
  if (!root->complete_nodeset)
    root->complete_nodeset = hwloc_bitmap_alloc();
}

static void
hwloc_discover_by_phase(struct hwloc_topology *topology,
			struct hwloc_disc_status *dstatus,
			const char *phasename __hwloc_attribute_unused)
{
  struct hwloc_backend *backend;
  hwloc_debug("%s phase discovery...\n", phasename);
  for(backend = topology->backends; backend; backend = backend->next) {
    if (dstatus->phase & dstatus->excluded_phases)
      break;
    if (!(backend->phases & dstatus->phase))
      continue;
    if (!backend->discover)
      continue;
    hwloc_debug("%s phase discovery in component %s...\n", phasename, backend->component->name);
    backend->discover(backend, dstatus);
    hwloc_debug_print_objects(0, topology->levels[0][0]);
  }
}


static int
hwloc_discover(struct hwloc_topology *topology,
	       struct hwloc_disc_status *dstatus)
{
  const char *env;

  topology->modified = 0; 

  topology->allowed_cpuset = hwloc_bitmap_alloc_full();
  topology->allowed_nodeset = hwloc_bitmap_alloc_full();

  

  

  

  

  if (topology->backend_phases & HWLOC_DISC_PHASE_GLOBAL) {
    
    struct hwloc_backend *global_backend = topology->backends;
    assert(global_backend);
    assert(global_backend->phases == HWLOC_DISC_PHASE_GLOBAL);

    
    hwloc_debug("GLOBAL phase discovery...\n");
    hwloc_debug("GLOBAL phase discovery with component %s...\n", global_backend->component->name);
    dstatus->phase = HWLOC_DISC_PHASE_GLOBAL;
    global_backend->discover(global_backend, dstatus);
    hwloc_debug_print_objects(0, topology->levels[0][0]);
  }
  

  if (topology->backend_phases & HWLOC_DISC_PHASE_CPU) {
    
    dstatus->phase = HWLOC_DISC_PHASE_CPU;
    hwloc_discover_by_phase(topology, dstatus, "CPU");
  }

  if (!(topology->backend_phases & (HWLOC_DISC_PHASE_GLOBAL|HWLOC_DISC_PHASE_CPU))) {
    hwloc_debug("No GLOBAL or CPU component phase found\n");
    
  }

  
  if (!topology->levels[0][0]->cpuset || hwloc_bitmap_iszero(topology->levels[0][0]->cpuset)) {
    hwloc_debug("%s", "No PU added by any CPU or GLOBAL component phase\n");
    errno = EINVAL;
    return -1;
  }

  
  if (topology->backend_phases & HWLOC_DISC_PHASE_MEMORY) {
    dstatus->phase = HWLOC_DISC_PHASE_MEMORY;
    hwloc_discover_by_phase(topology, dstatus, "MEMORY");
  }

  if (
      topology->binding_hooks.get_allowed_resources
      && topology->is_thissystem
      
      && !(dstatus->flags & HWLOC_DISC_STATUS_FLAG_GOT_ALLOWED_RESOURCES)
      
      && ((topology->flags & HWLOC_TOPOLOGY_FLAG_THISSYSTEM_ALLOWED_RESOURCES) != 0
	  || ((env = getenv("HWLOC_THISSYSTEM_ALLOWED_RESOURCES")) != NULL && atoi(env)))) {
    
    topology->binding_hooks.get_allowed_resources(topology);
    dstatus->flags |= HWLOC_DISC_STATUS_FLAG_GOT_ALLOWED_RESOURCES;
  }

  
  if (hwloc_bitmap_iszero(topology->levels[0][0]->complete_nodeset)) {
    hwloc_obj_t node;
    hwloc_debug("%s", "\nAdd missing single NUMA node\n");
    node = hwloc_alloc_setup_object(topology, HWLOC_OBJ_NUMANODE, 0);
    node->cpuset = hwloc_bitmap_dup(topology->levels[0][0]->cpuset);
    node->nodeset = hwloc_bitmap_alloc();
    
    hwloc_bitmap_set(node->nodeset, 0);
    memcpy(&node->attr->numanode, &topology->machine_memory, sizeof(topology->machine_memory));
    memset(&topology->machine_memory, 0, sizeof(topology->machine_memory));
    hwloc__insert_object_by_cpuset(topology, NULL, node, "core:defaultnumanode");
  } else {
    
    free(topology->machine_memory.page_types);
    memset(&topology->machine_memory, 0, sizeof(topology->machine_memory));
  }

  hwloc_debug("%s", "\nFixup root sets\n");
  hwloc_bitmap_and(topology->levels[0][0]->cpuset, topology->levels[0][0]->cpuset, topology->levels[0][0]->complete_cpuset);
  hwloc_bitmap_and(topology->levels[0][0]->nodeset, topology->levels[0][0]->nodeset, topology->levels[0][0]->complete_nodeset);

  hwloc_bitmap_and(topology->allowed_cpuset, topology->allowed_cpuset, topology->levels[0][0]->cpuset);
  hwloc_bitmap_and(topology->allowed_nodeset, topology->allowed_nodeset, topology->levels[0][0]->nodeset);

  hwloc_debug("%s", "\nPropagate sets\n");
  
  propagate_nodeset(topology->levels[0][0]);
  
  fixup_sets(topology->levels[0][0]);

  hwloc_debug_print_objects(0, topology->levels[0][0]);

  if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED)) {
    hwloc_debug("%s", "\nRemoving unauthorized sets from all sets\n");
    remove_unused_sets(topology, topology->levels[0][0]);
    hwloc_debug_print_objects(0, topology->levels[0][0]);
  }

  
  if (!hwloc_filter_check_keep_object(topology, topology->levels[0][0])
      && topology->levels[0][0]->first_child && !topology->levels[0][0]->first_child->next_sibling) {
    hwloc_obj_t oldroot = topology->levels[0][0];
    hwloc_obj_t newroot = oldroot->first_child;
    
    newroot->parent = NULL;
    topology->levels[0][0] = newroot;
    
    if (oldroot->memory_first_child)
      prepend_siblings_list(&newroot->memory_first_child, oldroot->memory_first_child, newroot);
    if (oldroot->io_first_child)
      prepend_siblings_list(&newroot->io_first_child, oldroot->io_first_child, newroot);
    if (oldroot->misc_first_child)
      prepend_siblings_list(&newroot->misc_first_child, oldroot->misc_first_child, newroot);
    
    hwloc_free_unlinked_object(oldroot);
  }

  

  
  hwloc_debug("%s", "\nOk, finished tweaking, now connect\n");
  if (hwloc_topology_reconnect(topology, 0) < 0)
    return -1;
  hwloc_debug_print_objects(0, topology->levels[0][0]);

  
  hwloc_pci_discovery_prepare(topology);

  if (topology->backend_phases & HWLOC_DISC_PHASE_PCI) {
    dstatus->phase = HWLOC_DISC_PHASE_PCI;
    hwloc_discover_by_phase(topology, dstatus, "PCI");
  }
  if (topology->backend_phases & HWLOC_DISC_PHASE_IO) {
    dstatus->phase = HWLOC_DISC_PHASE_IO;
    hwloc_discover_by_phase(topology, dstatus, "IO");
  }
  if (topology->backend_phases & HWLOC_DISC_PHASE_MISC) {
    dstatus->phase = HWLOC_DISC_PHASE_MISC;
    hwloc_discover_by_phase(topology, dstatus, "MISC");
  }
  if (topology->backend_phases & HWLOC_DISC_PHASE_ANNOTATE) {
    dstatus->phase = HWLOC_DISC_PHASE_ANNOTATE;
    hwloc_discover_by_phase(topology, dstatus, "ANNOTATE");
  }

  hwloc_pci_discovery_exit(topology); 

  if (getenv("HWLOC_DEBUG_SORT_CHILDREN"))
    hwloc_debug_sort_children(topology->levels[0][0]);

  

  hwloc_debug("%s", "\nRemoving bridge objects if needed\n");
  hwloc_filter_bridges(topology, topology->levels[0][0]);
  hwloc_debug_print_objects(0, topology->levels[0][0]);

  hwloc_debug("%s", "\nRemoving empty objects\n");
  remove_empty(topology, &topology->levels[0][0]);
  if (!topology->levels[0][0]) {
    if (HWLOC_SHOW_CRITICAL_ERRORS())
      fprintf(stderr, "hwloc: Topology became empty, aborting!\n");
    return -1;
  }
  if (hwloc_bitmap_iszero(topology->levels[0][0]->cpuset)) {
    if (HWLOC_SHOW_CRITICAL_ERRORS())
      fprintf(stderr, "hwloc: Topology does not contain any PU, aborting!\n");
    return -1;
  }
  if (hwloc_bitmap_iszero(topology->levels[0][0]->nodeset)) {
    if (HWLOC_SHOW_CRITICAL_ERRORS())
      fprintf(stderr, "hwloc: Topology does not contain any NUMA node, aborting!\n");
    return -1;
  }
  hwloc_debug_print_objects(0, topology->levels[0][0]);

  hwloc_debug("%s", "\nRemoving levels with HWLOC_TYPE_FILTER_KEEP_STRUCTURE\n");
  if (hwloc_filter_levels_keep_structure(topology) < 0)
    return -1;
  
  hwloc_debug_print_objects(0, topology->levels[0][0]);

  
  hwloc_debug("%s", "\nPropagate total memory up\n");
  propagate_total_memory(topology->levels[0][0]);

  
  hwloc_propagate_symmetric_subtree(topology, topology->levels[0][0]);

  
  hwloc_set_group_depth(topology);

  
  if (topology->backends
      && strcmp(topology->backends->component->name, "xml")
      && !getenv("HWLOC_DONT_ADD_VERSION_INFO")) {
    char *value;
    
    hwloc_obj_add_info(topology->levels[0][0], "hwlocVersion", HWLOC_VERSION);
    
    value = hwloc_progname(topology);
    if (value) {
      hwloc_obj_add_info(topology->levels[0][0], "ProcessName", value);
      free(value);
    }
  }

  return 0;
}


void
hwloc_topology_setup_defaults(struct hwloc_topology *topology)
{
  struct hwloc_obj *root_obj;

  
  memset(&topology->binding_hooks, 0, sizeof(topology->binding_hooks));
  memset(topology->support.discovery, 0, sizeof(*topology->support.discovery));
  memset(topology->support.cpubind, 0, sizeof(*topology->support.cpubind));
  memset(topology->support.membind, 0, sizeof(*topology->support.membind));
  memset(topology->support.misc, 0, sizeof(*topology->support.misc));

  
  topology->next_gp_index = 1; 
  topology->nb_levels = 1; 
  topology->levels[0] = hwloc_tma_malloc (topology->tma, sizeof (hwloc_obj_t));
  topology->level_nbobjects[0] = 1;

  
  topology->machine_memory.local_memory = 0;
  topology->machine_memory.page_types_len = 0;
  topology->machine_memory.page_types = NULL;

  
  topology->allowed_cpuset = NULL;
  topology->allowed_nodeset = NULL;

  
  memset(&topology->slevels, 0, sizeof(topology->slevels));
  
  HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_NUMANODE == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_NUMANODE));
  HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_MISC == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_MISC));
  HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_BRIDGE == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_BRIDGE));
  HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_PCIDEV == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_PCI_DEVICE));
  HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_OSDEV == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_OS_DEVICE));
  HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_MEMCACHE == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_MEMCACHE));

  
  hwloc_reset_normal_type_depths(topology);
  topology->type_depth[HWLOC_OBJ_NUMANODE] = HWLOC_TYPE_DEPTH_NUMANODE;
  topology->type_depth[HWLOC_OBJ_MISC] = HWLOC_TYPE_DEPTH_MISC;
  topology->type_depth[HWLOC_OBJ_BRIDGE] = HWLOC_TYPE_DEPTH_BRIDGE;
  topology->type_depth[HWLOC_OBJ_PCI_DEVICE] = HWLOC_TYPE_DEPTH_PCI_DEVICE;
  topology->type_depth[HWLOC_OBJ_OS_DEVICE] = HWLOC_TYPE_DEPTH_OS_DEVICE;
  topology->type_depth[HWLOC_OBJ_MEMCACHE] = HWLOC_TYPE_DEPTH_MEMCACHE;

  
  root_obj = hwloc_alloc_setup_object(topology, HWLOC_OBJ_MACHINE, 0);
  topology->levels[0][0] = root_obj;
}

static void hwloc__topology_filter_init(struct hwloc_topology *topology);


static int
hwloc__topology_init (struct hwloc_topology **topologyp,
		      unsigned nblevels,
		      struct hwloc_tma *tma)
{
  struct hwloc_topology *topology;

  topology = hwloc_tma_malloc (tma, sizeof (struct hwloc_topology));
  if(!topology)
    return -1;

  topology->tma = tma;

  hwloc_components_init(); 
  hwloc_topology_components_init(topology);
  hwloc_pci_discovery_init(topology); 

  
  topology->is_loaded = 0;
  topology->flags = 0;
  topology->is_thissystem = 1;
  topology->pid = 0;
  topology->userdata = NULL;
  topology->topology_abi = HWLOC_TOPOLOGY_ABI;
  topology->adopted_shmem_addr = NULL;
  topology->adopted_shmem_length = 0;

  topology->support.discovery = hwloc_tma_malloc(tma, sizeof(*topology->support.discovery));
  topology->support.cpubind = hwloc_tma_malloc(tma, sizeof(*topology->support.cpubind));
  topology->support.membind = hwloc_tma_malloc(tma, sizeof(*topology->support.membind));
  topology->support.misc = hwloc_tma_malloc(tma, sizeof(*topology->support.misc));

  topology->nb_levels_allocated = nblevels; 
  topology->levels = hwloc_tma_calloc(tma, topology->nb_levels_allocated * sizeof(*topology->levels));
  topology->level_nbobjects = hwloc_tma_calloc(tma, topology->nb_levels_allocated * sizeof(*topology->level_nbobjects));

  hwloc__topology_filter_init(topology);

  
  hwloc_internal_distances_init(topology);
  hwloc_internal_memattrs_init(topology);
  hwloc_internal_cpukinds_init(topology);

  topology->userdata_export_cb = NULL;
  topology->userdata_import_cb = NULL;
  topology->userdata_not_decoded = 0;

  
  hwloc_topology_setup_defaults(topology);

  *topologyp = topology;
  return 0;
}

int
hwloc_topology_init (struct hwloc_topology **topologyp)
{
  return hwloc__topology_init(topologyp,
			      16, 
			      NULL); 
}

int
hwloc_topology_set_pid(struct hwloc_topology *topology __hwloc_attribute_unused,
                       hwloc_pid_t pid __hwloc_attribute_unused)
{
  if (topology->is_loaded) {
    errno = EBUSY;
    return -1;
  }

  
#ifdef HWLOC_LINUX_SYS
  topology->pid = pid;
  return 0;
#else 
  errno = ENOSYS;
  return -1;
#endif 
}

int
hwloc_topology_set_synthetic(struct hwloc_topology *topology, const char *description)
{
  if (topology->is_loaded) {
    errno = EBUSY;
    return -1;
  }

  return hwloc_disc_component_force_enable(topology,
					   0 ,
					   "synthetic",
					   description, NULL, NULL);
}

int
hwloc_topology_set_xml(struct hwloc_topology *topology,
		       const char *xmlpath)
{
  if (topology->is_loaded) {
    errno = EBUSY;
    return -1;
  }

  return hwloc_disc_component_force_enable(topology,
					   0 ,
					   "xml",
					   xmlpath, NULL, NULL);
}

int
hwloc_topology_set_xmlbuffer(struct hwloc_topology *topology,
                             const char *xmlbuffer,
                             int size)
{
  if (topology->is_loaded) {
    errno = EBUSY;
    return -1;
  }

  return hwloc_disc_component_force_enable(topology,
					   0 ,
					   "xml", NULL,
					   xmlbuffer, (void*) (uintptr_t) size);
}

int
hwloc_topology_set_flags (struct hwloc_topology *topology, unsigned long flags)
{
  if (topology->is_loaded) {
    
    errno = EBUSY;
    return -1;
  }

  if (flags & ~(HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED
                |HWLOC_TOPOLOGY_FLAG_IS_THISSYSTEM
                |HWLOC_TOPOLOGY_FLAG_THISSYSTEM_ALLOWED_RESOURCES
                |HWLOC_TOPOLOGY_FLAG_IMPORT_SUPPORT
                |HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_CPUBINDING
                |HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_MEMBINDING
                |HWLOC_TOPOLOGY_FLAG_DONT_CHANGE_BINDING
                |HWLOC_TOPOLOGY_FLAG_NO_DISTANCES
                |HWLOC_TOPOLOGY_FLAG_NO_MEMATTRS
                |HWLOC_TOPOLOGY_FLAG_NO_CPUKINDS)) {
    errno = EINVAL;
    return -1;
  }

  if ((flags & (HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_CPUBINDING|HWLOC_TOPOLOGY_FLAG_IS_THISSYSTEM)) == HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_CPUBINDING) {
    
    errno = EINVAL;
    return -1;
  }
  if ((flags & (HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_MEMBINDING|HWLOC_TOPOLOGY_FLAG_IS_THISSYSTEM)) == HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_MEMBINDING) {
    
    errno = EINVAL;
    return -1;
  }

  topology->flags = flags;
  return 0;
}

unsigned long
hwloc_topology_get_flags (struct hwloc_topology *topology)
{
  return topology->flags;
}

static void
hwloc__topology_filter_init(struct hwloc_topology *topology)
{
  hwloc_obj_type_t type;
  
  for(type = HWLOC_OBJ_TYPE_MIN; type < HWLOC_OBJ_TYPE_MAX; type++)
    topology->type_filter[type] = HWLOC_TYPE_FILTER_KEEP_ALL;
  topology->type_filter[HWLOC_OBJ_L1ICACHE] = HWLOC_TYPE_FILTER_KEEP_NONE;
  topology->type_filter[HWLOC_OBJ_L2ICACHE] = HWLOC_TYPE_FILTER_KEEP_NONE;
  topology->type_filter[HWLOC_OBJ_L3ICACHE] = HWLOC_TYPE_FILTER_KEEP_NONE;
  topology->type_filter[HWLOC_OBJ_MEMCACHE] = HWLOC_TYPE_FILTER_KEEP_NONE;
  topology->type_filter[HWLOC_OBJ_GROUP] = HWLOC_TYPE_FILTER_KEEP_STRUCTURE;
  topology->type_filter[HWLOC_OBJ_MISC] = HWLOC_TYPE_FILTER_KEEP_NONE;
  topology->type_filter[HWLOC_OBJ_BRIDGE] = HWLOC_TYPE_FILTER_KEEP_NONE;
  topology->type_filter[HWLOC_OBJ_PCI_DEVICE] = HWLOC_TYPE_FILTER_KEEP_NONE;
  topology->type_filter[HWLOC_OBJ_OS_DEVICE] = HWLOC_TYPE_FILTER_KEEP_NONE;
}

static int
hwloc__topology_set_type_filter(struct hwloc_topology *topology, hwloc_obj_type_t type, enum hwloc_type_filter_e filter)
{
  if (type == HWLOC_OBJ_PU || type == HWLOC_OBJ_NUMANODE || type == HWLOC_OBJ_MACHINE) {
    if (filter != HWLOC_TYPE_FILTER_KEEP_ALL) {
      
      errno = EINVAL;
      return -1;
    }
  } else if (hwloc__obj_type_is_special(type)) {
    if (filter == HWLOC_TYPE_FILTER_KEEP_STRUCTURE) {
      
      errno = EINVAL;
      return -1;
    }
  } else if (type == HWLOC_OBJ_GROUP) {
    if (filter == HWLOC_TYPE_FILTER_KEEP_ALL) {
      
      errno = EINVAL;
      return -1;
    }
  }

  
  if (!hwloc__obj_type_is_special(type) && filter == HWLOC_TYPE_FILTER_KEEP_IMPORTANT)
    filter = HWLOC_TYPE_FILTER_KEEP_ALL;

  topology->type_filter[type] = filter;
  return 0;
}

int
hwloc_topology_set_type_filter(struct hwloc_topology *topology, hwloc_obj_type_t type, enum hwloc_type_filter_e filter)
{
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_TYPE_MIN == 0);
  if ((unsigned) type >= HWLOC_OBJ_TYPE_MAX) {
    errno = EINVAL;
    return -1;
  }
  if (topology->is_loaded) {
    errno = EBUSY;
    return -1;
  }
  return hwloc__topology_set_type_filter(topology, type, filter);
}

int
hwloc_topology_set_all_types_filter(struct hwloc_topology *topology, enum hwloc_type_filter_e filter)
{
  hwloc_obj_type_t type;
  if (topology->is_loaded) {
    errno = EBUSY;
    return -1;
  }
  for(type = HWLOC_OBJ_TYPE_MIN; type < HWLOC_OBJ_TYPE_MAX; type++)
    hwloc__topology_set_type_filter(topology, type, filter);
  return 0;
}

int
hwloc_topology_set_cache_types_filter(hwloc_topology_t topology, enum hwloc_type_filter_e filter)
{
  unsigned i;
  if (topology->is_loaded) {
    errno = EBUSY;
    return -1;
  }
  for(i=HWLOC_OBJ_L1CACHE; i<=HWLOC_OBJ_L3ICACHE; i++)
    hwloc__topology_set_type_filter(topology, (hwloc_obj_type_t) i, filter);
  return 0;
}

int
hwloc_topology_set_icache_types_filter(hwloc_topology_t topology, enum hwloc_type_filter_e filter)
{
  unsigned i;
  if (topology->is_loaded) {
    errno = EBUSY;
    return -1;
  }
  for(i=HWLOC_OBJ_L1ICACHE; i<=HWLOC_OBJ_L3ICACHE; i++)
    hwloc__topology_set_type_filter(topology, (hwloc_obj_type_t) i, filter);
  return 0;
}

int
hwloc_topology_set_io_types_filter(hwloc_topology_t topology, enum hwloc_type_filter_e filter)
{
  if (topology->is_loaded) {
    errno = EBUSY;
    return -1;
  }
  hwloc__topology_set_type_filter(topology, HWLOC_OBJ_BRIDGE, filter);
  hwloc__topology_set_type_filter(topology, HWLOC_OBJ_PCI_DEVICE, filter);
  hwloc__topology_set_type_filter(topology, HWLOC_OBJ_OS_DEVICE, filter);
  return 0;
}

int
hwloc_topology_get_type_filter(struct hwloc_topology *topology, hwloc_obj_type_t type, enum hwloc_type_filter_e *filterp)
{
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_TYPE_MIN == 0);
  if ((unsigned) type >= HWLOC_OBJ_TYPE_MAX) {
    errno = EINVAL;
    return -1;
  }
  *filterp = topology->type_filter[type];
  return 0;
}

void
hwloc_topology_clear (struct hwloc_topology *topology)
{
  
  unsigned l;

  
  hwloc_internal_cpukinds_destroy(topology);
  hwloc_internal_distances_destroy(topology);
  hwloc_internal_memattrs_destroy(topology);

  hwloc_free_object_and_children(topology->levels[0][0]);
  hwloc_bitmap_free(topology->allowed_cpuset);
  hwloc_bitmap_free(topology->allowed_nodeset);
  for (l=0; l<topology->nb_levels; l++)
    free(topology->levels[l]);
  for(l=0; l<HWLOC_NR_SLEVELS; l++)
    free(topology->slevels[l].objs);
  free(topology->machine_memory.page_types);
}

void
hwloc_topology_destroy (struct hwloc_topology *topology)
{
  if (topology->adopted_shmem_addr) {
    hwloc__topology_disadopt(topology);
    return;
  }

  hwloc_backends_disable_all(topology);
  hwloc_topology_components_fini(topology);
  hwloc_components_fini();

  hwloc_topology_clear(topology);

  free(topology->levels);
  free(topology->level_nbobjects);

  free(topology->support.discovery);
  free(topology->support.cpubind);
  free(topology->support.membind);
  free(topology->support.misc);
  free(topology);
}

int
hwloc_topology_load (struct hwloc_topology *topology)
{
  struct hwloc_disc_status dstatus;
  const char *env;
  unsigned i;
  int err;

  if (topology->is_loaded) {
    errno = EBUSY;
    return -1;
  }

  
  if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_NO_DISTANCES))
    hwloc_internal_distances_prepare(topology);
  if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_NO_MEMATTRS))
    hwloc_internal_memattrs_prepare(topology);

  
  topology->want_some_cpu_caches = 0;
  for(i=HWLOC_OBJ_L1CACHE; i<=HWLOC_OBJ_L3ICACHE; i++)
    if (topology->type_filter[i] != HWLOC_TYPE_FILTER_KEEP_NONE) {
      topology->want_some_cpu_caches = 1;
      break;
    }

  if (getenv("HWLOC_XML_USERDATA_NOT_DECODED"))
    topology->userdata_not_decoded = 1;

  
  if (!getenv("HWLOC_COMPONENTS")) {
    
    if (!topology->backends) {
      const char *fsroot_path_env = getenv("HWLOC_FSROOT");
      if (fsroot_path_env)
	hwloc_disc_component_force_enable(topology,
					  1 ,
					  "linux",
					  NULL , NULL, NULL);
    }
    if (!topology->backends) {
      const char *cpuid_path_env = getenv("HWLOC_CPUID_PATH");
      if (cpuid_path_env)
	hwloc_disc_component_force_enable(topology,
					  1 ,
					  "x86",
					  NULL , NULL, NULL);
    }
    if (!topology->backends) {
      const char *synthetic_env = getenv("HWLOC_SYNTHETIC");
      if (synthetic_env)
	hwloc_disc_component_force_enable(topology,
					  1 ,
					  "synthetic",
					  synthetic_env, NULL, NULL);
    }
    if (!topology->backends) {
      const char *xmlpath_env = getenv("HWLOC_XMLFILE");
      if (xmlpath_env)
	hwloc_disc_component_force_enable(topology,
					  1 ,
					  "xml",
					  xmlpath_env, NULL, NULL);
    }
  }

  dstatus.excluded_phases = 0;
  dstatus.flags = 0; 

  env = getenv("HWLOC_ALLOW");
  if (env && !strcmp(env, "all"))
    
    dstatus.flags |= HWLOC_DISC_STATUS_FLAG_GOT_ALLOWED_RESOURCES;

  
  hwloc_disc_components_enable_others(topology);
  
  hwloc_backends_is_thissystem(topology);
  hwloc_backends_find_callbacks(topology);
  
  hwloc_set_binding_hooks(topology);

  
  err = hwloc_discover(topology, &dstatus);
  if (err < 0)
    goto out;

#ifndef HWLOC_DEBUG
  if (getenv("HWLOC_DEBUG_CHECK"))
#endif
    hwloc_topology_check(topology);

  if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_NO_CPUKINDS)) {
    
    hwloc_internal_cpukinds_rank(topology);
  }

  if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_NO_DISTANCES)) {
    
    hwloc_internal_distances_invalidate_cached_objs(topology);
    
    hwloc_internal_distances_refresh(topology);
  }

  if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_NO_MEMATTRS)) {
    int force_memtiers = (getenv("HWLOC_MEMTIERS_REFRESH") != NULL);
    
    hwloc_internal_memattrs_need_refresh(topology);
    hwloc_internal_memattrs_refresh(topology);
    
    if (force_memtiers || strcmp(topology->backends->component->name, "xml"))
      hwloc_internal_memattrs_guess_memory_tiers(topology, force_memtiers);
  }

  topology->is_loaded = 1;

  if (topology->flags & HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_CPUBINDING) {
    
    hwloc_bitmap_t set = hwloc_bitmap_alloc();
    if (set) {
      err = hwloc_get_cpubind(topology, set, HWLOC_CPUBIND_STRICT);
      if (!err)
        hwloc_topology_restrict(topology, set, 0);
      hwloc_bitmap_free(set);
    }
  }
  if (topology->flags & HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_MEMBINDING) {
    
    hwloc_bitmap_t set = hwloc_bitmap_alloc();
    hwloc_membind_policy_t policy;
    if (set) {
      err = hwloc_get_membind(topology, set, &policy, HWLOC_MEMBIND_STRICT | HWLOC_MEMBIND_BYNODESET);
      if (!err)
        hwloc_topology_restrict(topology, set, HWLOC_RESTRICT_FLAG_BYNODESET);
      hwloc_bitmap_free(set);
    }
  }

  if (topology->backend_phases & HWLOC_DISC_PHASE_TWEAK) {
    dstatus.phase = HWLOC_DISC_PHASE_TWEAK;
    hwloc_discover_by_phase(topology, &dstatus, "TWEAK");
  }

  return 0;

 out:
  hwloc_pci_discovery_exit(topology);
  hwloc_topology_clear(topology);
  hwloc_topology_setup_defaults(topology);
  hwloc_backends_disable_all(topology);
  return -1;
}


static void
restrict_object_by_cpuset(hwloc_topology_t topology, unsigned long flags, hwloc_obj_t *pobj,
			  hwloc_bitmap_t droppedcpuset, hwloc_bitmap_t droppednodeset)
{
  hwloc_obj_t obj = *pobj, child, *pchild;
  int modified = 0;

  if (hwloc_bitmap_intersects(obj->complete_cpuset, droppedcpuset)) {
    hwloc_bitmap_andnot(obj->cpuset, obj->cpuset, droppedcpuset);
    hwloc_bitmap_andnot(obj->complete_cpuset, obj->complete_cpuset, droppedcpuset);
    modified = 1;
  }
  if (droppednodeset && hwloc_bitmap_intersects(obj->complete_nodeset, droppednodeset)) {
    hwloc_bitmap_andnot(obj->nodeset, obj->nodeset, droppednodeset);
    hwloc_bitmap_andnot(obj->complete_nodeset, obj->complete_nodeset, droppednodeset);
    modified = 1;
  }

  if (modified) {
    for_each_child_safe(child, obj, pchild)
      restrict_object_by_cpuset(topology, flags, pchild, droppedcpuset, droppednodeset);
    
    hwloc__reorder_children(obj);

    for_each_memory_child_safe(child, obj, pchild)
      restrict_object_by_cpuset(topology, flags, pchild, droppedcpuset, droppednodeset);
    

    
  }

  if (!obj->first_child && !obj->memory_first_child 
      && hwloc_bitmap_iszero(obj->cpuset)
      && (obj->type != HWLOC_OBJ_NUMANODE || (flags & HWLOC_RESTRICT_FLAG_REMOVE_CPULESS))) {
    
    hwloc_debug("%s", "\nRemoving object during restrict by cpuset");
    hwloc_debug_print_object(0, obj);

    if (!(flags & HWLOC_RESTRICT_FLAG_ADAPT_IO)) {
      hwloc_free_object_siblings_and_children(obj->io_first_child);
      obj->io_first_child = NULL;
    }
    if (!(flags & HWLOC_RESTRICT_FLAG_ADAPT_MISC)) {
      hwloc_free_object_siblings_and_children(obj->misc_first_child);
      obj->misc_first_child = NULL;
    }
    assert(!obj->first_child);
    assert(!obj->memory_first_child);
    unlink_and_free_single_object(pobj);
    topology->modified = 1;
  }
}


static void
restrict_object_by_nodeset(hwloc_topology_t topology, unsigned long flags, hwloc_obj_t *pobj,
			   hwloc_bitmap_t droppedcpuset, hwloc_bitmap_t droppednodeset)
{
  hwloc_obj_t obj = *pobj, child, *pchild;
  int modified = 0;

  if (hwloc_bitmap_intersects(obj->complete_nodeset, droppednodeset)) {
    hwloc_bitmap_andnot(obj->nodeset, obj->nodeset, droppednodeset);
    hwloc_bitmap_andnot(obj->complete_nodeset, obj->complete_nodeset, droppednodeset);
    modified = 1;
  }
  if (droppedcpuset && hwloc_bitmap_intersects(obj->complete_cpuset, droppedcpuset)) {
    hwloc_bitmap_andnot(obj->cpuset, obj->cpuset, droppedcpuset);
    hwloc_bitmap_andnot(obj->complete_cpuset, obj->complete_cpuset, droppedcpuset);
    modified = 1;
  }

  if (modified) {
    for_each_child_safe(child, obj, pchild)
      restrict_object_by_nodeset(topology, flags, pchild, droppedcpuset, droppednodeset);
    if (flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS)
      
      hwloc__reorder_children(obj);

    for_each_memory_child_safe(child, obj, pchild)
      restrict_object_by_nodeset(topology, flags, pchild, droppedcpuset, droppednodeset);
    

    
  }

  if (!obj->first_child && !obj->memory_first_child 
      && hwloc_bitmap_iszero(obj->nodeset)
      && (obj->type != HWLOC_OBJ_PU || (flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS))) {
    
    hwloc_debug("%s", "\nRemoving object during restrict by nodeset");
    hwloc_debug_print_object(0, obj);

    if (!(flags & HWLOC_RESTRICT_FLAG_ADAPT_IO)) {
      hwloc_free_object_siblings_and_children(obj->io_first_child);
      obj->io_first_child = NULL;
    }
    if (!(flags & HWLOC_RESTRICT_FLAG_ADAPT_MISC)) {
      hwloc_free_object_siblings_and_children(obj->misc_first_child);
      obj->misc_first_child = NULL;
    }
    assert(!obj->first_child);
    assert(!obj->memory_first_child);
    unlink_and_free_single_object(pobj);
    topology->modified = 1;
  }
}

int
hwloc_topology_restrict(struct hwloc_topology *topology, hwloc_const_bitmap_t set, unsigned long flags)
{
  hwloc_bitmap_t droppedcpuset, droppednodeset;

  if (!topology->is_loaded) {
    errno = EINVAL;
    return -1;
  }
  if (topology->adopted_shmem_addr) {
    errno = EPERM;
    return -1;
  }

  if (flags & ~(HWLOC_RESTRICT_FLAG_REMOVE_CPULESS
		|HWLOC_RESTRICT_FLAG_ADAPT_MISC|HWLOC_RESTRICT_FLAG_ADAPT_IO
		|HWLOC_RESTRICT_FLAG_BYNODESET|HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS)) {
    errno = EINVAL;
    return -1;
  }

  if (flags & HWLOC_RESTRICT_FLAG_BYNODESET) {
    
    if (flags & HWLOC_RESTRICT_FLAG_REMOVE_CPULESS) {
      errno = EINVAL;
      return -1;
    }
  } else {
    
    if (flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS) {
      errno = EINVAL;
      return -1;
    }
  }

  
  if (((flags & HWLOC_RESTRICT_FLAG_BYNODESET) && !hwloc_bitmap_intersects(set, topology->allowed_nodeset))
      || (!(flags & HWLOC_RESTRICT_FLAG_BYNODESET) && !hwloc_bitmap_intersects(set, topology->allowed_cpuset))) {
    errno = EINVAL; 
    return -1;
  }

  droppedcpuset = hwloc_bitmap_alloc();
  droppednodeset = hwloc_bitmap_alloc();
  if (!droppedcpuset || !droppednodeset) {
    hwloc_bitmap_free(droppedcpuset);
    hwloc_bitmap_free(droppednodeset);
    return -1;
  }

  if (flags & HWLOC_RESTRICT_FLAG_BYNODESET) {
    
    hwloc_bitmap_not(droppednodeset, set);
    
    if (flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS) {
      hwloc_obj_t pu = hwloc_get_obj_by_type(topology, HWLOC_OBJ_PU, 0);
      assert(pu);
      do {
	
	if (hwloc_bitmap_iszero(pu->cpuset)
	    || hwloc_bitmap_isincluded(pu->nodeset, droppednodeset))
	  hwloc_bitmap_set(droppedcpuset, pu->os_index);
	pu = pu->next_cousin;
      } while (pu);

      
      if (hwloc_bitmap_isincluded(topology->allowed_cpuset, droppedcpuset)) {
	errno = EINVAL; 
	hwloc_bitmap_free(droppedcpuset);
	hwloc_bitmap_free(droppednodeset);
	return -1;
      }
    }
    
    if (!(flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS)
	|| hwloc_bitmap_iszero(droppedcpuset)) {
      hwloc_bitmap_free(droppedcpuset);
      droppedcpuset = NULL;
    }

    
    restrict_object_by_nodeset(topology, flags, &topology->levels[0][0], droppedcpuset, droppednodeset);
    hwloc_bitmap_andnot(topology->allowed_nodeset, topology->allowed_nodeset, droppednodeset);
    if (droppedcpuset)
      hwloc_bitmap_andnot(topology->allowed_cpuset, topology->allowed_cpuset, droppedcpuset);

  } else {
    
    hwloc_bitmap_not(droppedcpuset, set);
    
    if (flags & HWLOC_RESTRICT_FLAG_REMOVE_CPULESS) {
      hwloc_obj_t node = hwloc_get_obj_by_type(topology, HWLOC_OBJ_NUMANODE, 0);
      assert(node);
      do {
	
	if (hwloc_bitmap_iszero(node->cpuset)
	    || hwloc_bitmap_isincluded(node->cpuset, droppedcpuset))
	  hwloc_bitmap_set(droppednodeset, node->os_index);
	node = node->next_cousin;
      } while (node);

      
      if (hwloc_bitmap_isincluded(topology->allowed_nodeset, droppednodeset)) {
	errno = EINVAL; 
	hwloc_bitmap_free(droppedcpuset);
	hwloc_bitmap_free(droppednodeset);
	return -1;
      }
    }
    
    if (!(flags & HWLOC_RESTRICT_FLAG_REMOVE_CPULESS)
	|| hwloc_bitmap_iszero(droppednodeset)) {
      hwloc_bitmap_free(droppednodeset);
      droppednodeset = NULL;
    }

    
    restrict_object_by_cpuset(topology, flags, &topology->levels[0][0], droppedcpuset, droppednodeset);
    hwloc_bitmap_andnot(topology->allowed_cpuset, topology->allowed_cpuset, droppedcpuset);
    if (droppednodeset)
      hwloc_bitmap_andnot(topology->allowed_nodeset, topology->allowed_nodeset, droppednodeset);
  }

  hwloc_bitmap_free(droppedcpuset);
  hwloc_bitmap_free(droppednodeset);

  if (hwloc_filter_levels_keep_structure(topology) < 0) 
    goto out;

  
  if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_NO_DISTANCES))
    hwloc_internal_distances_invalidate_cached_objs(topology);
  if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_NO_MEMATTRS))
    hwloc_internal_memattrs_need_refresh(topology);
  if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_NO_CPUKINDS))
    hwloc_internal_cpukinds_restrict(topology);


  hwloc_propagate_symmetric_subtree(topology, topology->levels[0][0]);
  propagate_total_memory(topology->levels[0][0]);

#ifndef HWLOC_DEBUG
  if (getenv("HWLOC_DEBUG_CHECK"))
#endif
    hwloc_topology_check(topology);

  return 0;

 out:
  
   hwloc_topology_clear(topology);
   hwloc_topology_setup_defaults(topology);
   return -1;
}

int
hwloc_topology_allow(struct hwloc_topology *topology,
		     hwloc_const_cpuset_t cpuset, hwloc_const_nodeset_t nodeset,
		     unsigned long flags)
{
  if (!topology->is_loaded)
    goto einval;

  if (topology->adopted_shmem_addr) {
    errno = EPERM;
    goto error;
  }

  if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED))
    goto einval;

  if (flags & ~(HWLOC_ALLOW_FLAG_ALL|HWLOC_ALLOW_FLAG_LOCAL_RESTRICTIONS|HWLOC_ALLOW_FLAG_CUSTOM))
    goto einval;

  switch (flags) {
  case HWLOC_ALLOW_FLAG_ALL: {
    if (cpuset || nodeset)
      goto einval;
    hwloc_bitmap_copy(topology->allowed_cpuset, hwloc_get_root_obj(topology)->complete_cpuset);
    hwloc_bitmap_copy(topology->allowed_nodeset, hwloc_get_root_obj(topology)->complete_nodeset);
    break;
  }
  case HWLOC_ALLOW_FLAG_LOCAL_RESTRICTIONS: {
    if (cpuset || nodeset)
      goto einval;
    if (!topology->is_thissystem)
      goto einval;
    if (!topology->binding_hooks.get_allowed_resources) {
      errno = ENOSYS;
      goto error;
    }
    topology->binding_hooks.get_allowed_resources(topology);
    
    hwloc_bitmap_and(topology->allowed_cpuset, topology->allowed_cpuset, hwloc_get_root_obj(topology)->cpuset);
    hwloc_bitmap_and(topology->allowed_nodeset, topology->allowed_nodeset, hwloc_get_root_obj(topology)->nodeset);
    break;
  }
  case HWLOC_ALLOW_FLAG_CUSTOM: {
    if (cpuset) {
      
      if (!hwloc_bitmap_intersects(hwloc_get_root_obj(topology)->cpuset, cpuset))
	goto einval;
      hwloc_bitmap_and(topology->allowed_cpuset, hwloc_get_root_obj(topology)->cpuset, cpuset);
    }
    if (nodeset) {
      
      if (!hwloc_bitmap_intersects(hwloc_get_root_obj(topology)->nodeset, nodeset))
	goto einval;
      hwloc_bitmap_and(topology->allowed_nodeset, hwloc_get_root_obj(topology)->nodeset, nodeset);
    }
    break;
  }
  default:
    goto einval;
  }

  return 0;

 einval:
  errno = EINVAL;
 error:
  return -1;
}

int
hwloc_topology_refresh(struct hwloc_topology *topology)
{
  if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_NO_CPUKINDS))
    hwloc_internal_cpukinds_rank(topology);
  if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_NO_DISTANCES))
    hwloc_internal_distances_refresh(topology);
  if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_NO_MEMATTRS))
    hwloc_internal_memattrs_refresh(topology);
  return 0;
}

int
hwloc_topology_is_thissystem(struct hwloc_topology *topology)
{
  return topology->is_thissystem;
}

int
hwloc_topology_get_depth(struct hwloc_topology *topology)
{
  return (int) topology->nb_levels;
}

const struct hwloc_topology_support *
hwloc_topology_get_support(struct hwloc_topology * topology)
{
  return &topology->support;
}

void hwloc_topology_set_userdata(struct hwloc_topology * topology, const void *userdata)
{
  topology->userdata = (void *) userdata;
}

void * hwloc_topology_get_userdata(struct hwloc_topology * topology)
{
  return topology->userdata;
}

hwloc_const_cpuset_t
hwloc_topology_get_complete_cpuset(hwloc_topology_t topology)
{
  return hwloc_get_root_obj(topology)->complete_cpuset;
}

hwloc_const_cpuset_t
hwloc_topology_get_topology_cpuset(hwloc_topology_t topology)
{
  return hwloc_get_root_obj(topology)->cpuset;
}

hwloc_const_cpuset_t
hwloc_topology_get_allowed_cpuset(hwloc_topology_t topology)
{
  return topology->allowed_cpuset;
}

hwloc_const_nodeset_t
hwloc_topology_get_complete_nodeset(hwloc_topology_t topology)
{
  return hwloc_get_root_obj(topology)->complete_nodeset;
}

hwloc_const_nodeset_t
hwloc_topology_get_topology_nodeset(hwloc_topology_t topology)
{
  return hwloc_get_root_obj(topology)->nodeset;
}

hwloc_const_nodeset_t
hwloc_topology_get_allowed_nodeset(hwloc_topology_t topology)
{
  return topology->allowed_nodeset;
}




#ifndef NDEBUG 

static void
hwloc__check_child_siblings(hwloc_obj_t parent, hwloc_obj_t *array,
			    unsigned arity, unsigned i,
			    hwloc_obj_t child, hwloc_obj_t prev)
{
  assert(child->parent == parent);

  assert(child->sibling_rank == i);
  if (array)
    assert(child == array[i]);

  if (prev)
    assert(prev->next_sibling == child);
  assert(child->prev_sibling == prev);

  if (!i)
    assert(child->prev_sibling == NULL);
  else
    assert(child->prev_sibling != NULL);

  if (i == arity-1)
    assert(child->next_sibling == NULL);
  else
    assert(child->next_sibling != NULL);
}

static void
hwloc__check_object(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t obj);


static void
hwloc__check_normal_children(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t parent)
{
  hwloc_obj_t child, prev;
  unsigned j;

  if (!parent->arity) {
    
    assert(!parent->children);
    assert(!parent->first_child);
    assert(!parent->last_child);
    return;
  }
  
  assert(parent->children);
  assert(parent->first_child);
  assert(parent->last_child);

  
  for(prev = NULL, child = parent->first_child, j = 0;
      child;
      prev = child, child = child->next_sibling, j++) {
    
    assert(hwloc__obj_type_is_normal(child->type));
    
    assert(child->depth > parent->depth);
    
    hwloc__check_child_siblings(parent, parent->children, parent->arity, j, child, prev);
    
    hwloc__check_object(topology, gp_indexes, child);
  }
  
  assert(j == parent->arity);

  assert(parent->first_child == parent->children[0]);
  assert(parent->last_child == parent->children[parent->arity-1]);

  
  if (parent->type == HWLOC_OBJ_PU)
    assert(!parent->arity);
}

static void
hwloc__check_children_cpusets(hwloc_topology_t topology __hwloc_attribute_unused, hwloc_obj_t obj)
{
  
  hwloc_obj_t child;
  int prev_first, prev_empty;

  if (obj->type == HWLOC_OBJ_PU) {
    
    assert(hwloc_bitmap_weight(obj->cpuset) == 1);
    assert(hwloc_bitmap_first(obj->cpuset) == (int) obj->os_index);
    assert(hwloc_bitmap_weight(obj->complete_cpuset) == 1);
    assert(hwloc_bitmap_first(obj->complete_cpuset) == (int) obj->os_index);
    if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED)) {
      assert(hwloc_bitmap_isset(topology->allowed_cpuset, (int) obj->os_index));
    }
    assert(!obj->arity);
  } else if (hwloc__obj_type_is_memory(obj->type)) {
    
    assert(hwloc_bitmap_isequal(obj->parent->cpuset, obj->cpuset));
    assert(!obj->arity);
  } else if (!hwloc__obj_type_is_special(obj->type)) {
    hwloc_bitmap_t set;
    
    set = hwloc_bitmap_alloc();
    for_each_child(child, obj) {
      assert(!hwloc_bitmap_intersects(set, child->cpuset));
      hwloc_bitmap_or(set, set, child->cpuset);
    }
    assert(hwloc_bitmap_isequal(set, obj->cpuset));
    hwloc_bitmap_free(set);
  }

  
  for_each_memory_child(child, obj)
    assert(hwloc_bitmap_isequal(obj->cpuset, child->cpuset));

  
  prev_first = -1; 
  prev_empty = 0; 
  for_each_child(child, obj) {
    int first = hwloc_bitmap_first(child->complete_cpuset);
    if (first >= 0) {
      assert(!prev_empty); 
      assert(prev_first < first);
    } else {
      prev_empty = 1;
    }
    prev_first = first;
  }
}

static void
hwloc__check_memory_children(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t parent)
{
  unsigned j;
  hwloc_obj_t child, prev;

  if (!parent->memory_arity) {
    
    assert(!parent->memory_first_child);
    return;
  }
  
  assert(parent->memory_first_child);

  for(prev = NULL, child = parent->memory_first_child, j = 0;
      child;
      prev = child, child = child->next_sibling, j++) {
    assert(hwloc__obj_type_is_memory(child->type));
    
    hwloc__check_child_siblings(parent, NULL, parent->memory_arity, j, child, prev);
    
    assert(!child->first_child);
    assert(!child->io_first_child);
    hwloc__check_object(topology, gp_indexes, child);
  }
  
  assert(j == parent->memory_arity);

  
  if (parent->type == HWLOC_OBJ_NUMANODE)
    assert(!parent->memory_arity);
}

static void
hwloc__check_io_children(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t parent)
{
  unsigned j;
  hwloc_obj_t child, prev;

  if (!parent->io_arity) {
    
    assert(!parent->io_first_child);
    return;
  }
  
  assert(parent->io_first_child);

  for(prev = NULL, child = parent->io_first_child, j = 0;
      child;
      prev = child, child = child->next_sibling, j++) {
    
    assert(hwloc__obj_type_is_io(child->type));
    
    hwloc__check_child_siblings(parent, NULL, parent->io_arity, j, child, prev);
    
    assert(!child->first_child);
    assert(!child->memory_first_child);
    hwloc__check_object(topology, gp_indexes, child);
  }
  
  assert(j == parent->io_arity);
}

static void
hwloc__check_misc_children(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t parent)
{
  unsigned j;
  hwloc_obj_t child, prev;

  if (!parent->misc_arity) {
    
    assert(!parent->misc_first_child);
    return;
  }
  
  assert(parent->misc_first_child);

  for(prev = NULL, child = parent->misc_first_child, j = 0;
      child;
      prev = child, child = child->next_sibling, j++) {
    
    assert(child->type == HWLOC_OBJ_MISC);
    
    hwloc__check_child_siblings(parent, NULL, parent->misc_arity, j, child, prev);
    
    assert(!child->first_child);
    assert(!child->memory_first_child);
    assert(!child->io_first_child);
    hwloc__check_object(topology, gp_indexes, child);
  }
  
  assert(j == parent->misc_arity);
}

static void
hwloc__check_object(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t obj)
{
  hwloc_uint64_t total_memory;
  hwloc_obj_t child;

  assert(!hwloc_bitmap_isset(gp_indexes, obj->gp_index));
  hwloc_bitmap_set(gp_indexes, obj->gp_index);

  HWLOC_BUILD_ASSERT(HWLOC_OBJ_TYPE_MIN == 0);
  assert((unsigned) obj->type < HWLOC_OBJ_TYPE_MAX);

  assert(hwloc_filter_check_keep_object(topology, obj));

  
  if (hwloc__obj_type_is_special(obj->type)) {
    assert(!obj->cpuset);
    if (obj->type == HWLOC_OBJ_BRIDGE)
      assert(obj->depth == HWLOC_TYPE_DEPTH_BRIDGE);
    else if (obj->type == HWLOC_OBJ_PCI_DEVICE)
      assert(obj->depth == HWLOC_TYPE_DEPTH_PCI_DEVICE);
    else if (obj->type == HWLOC_OBJ_OS_DEVICE)
      assert(obj->depth == HWLOC_TYPE_DEPTH_OS_DEVICE);
    else if (obj->type == HWLOC_OBJ_MISC)
      assert(obj->depth == HWLOC_TYPE_DEPTH_MISC);
  } else {
    assert(obj->cpuset);
    if (obj->type == HWLOC_OBJ_NUMANODE)
      assert(obj->depth == HWLOC_TYPE_DEPTH_NUMANODE);
    else if (obj->type == HWLOC_OBJ_MEMCACHE)
      assert(obj->depth == HWLOC_TYPE_DEPTH_MEMCACHE);
    else
      assert(obj->depth >= 0);
  }

  
  if (obj->type == HWLOC_OBJ_GROUP) {
    assert(obj->attr->group.depth != (unsigned) -1);
  }

  
  assert(!!obj->cpuset == !!obj->complete_cpuset);
  assert(!!obj->cpuset == !!obj->nodeset);
  assert(!!obj->nodeset == !!obj->complete_nodeset);

  
  if (obj->cpuset) {
    assert(hwloc_bitmap_isincluded(obj->cpuset, obj->complete_cpuset));
    assert(hwloc_bitmap_isincluded(obj->nodeset, obj->complete_nodeset));
  }

  
  if (hwloc__obj_type_is_cache(obj->type)) {
    if (hwloc__obj_type_is_icache(obj->type))
      assert(obj->attr->cache.type == HWLOC_OBJ_CACHE_INSTRUCTION);
    else if (hwloc__obj_type_is_dcache(obj->type))
      assert(obj->attr->cache.type == HWLOC_OBJ_CACHE_DATA
	     || obj->attr->cache.type == HWLOC_OBJ_CACHE_UNIFIED);
    else
      assert(0);
    assert(hwloc_cache_type_by_depth_type(obj->attr->cache.depth, obj->attr->cache.type) == obj->type);
  }

  
  total_memory = 0;
  if (obj->type == HWLOC_OBJ_NUMANODE)
    total_memory += obj->attr->numanode.local_memory;
  for_each_child(child, obj) {
    total_memory += child->total_memory;
  }
  for_each_memory_child(child, obj) {
    total_memory += child->total_memory;
  }
  assert(total_memory == obj->total_memory);

  
  hwloc__check_normal_children(topology, gp_indexes, obj);
  hwloc__check_memory_children(topology, gp_indexes, obj);
  hwloc__check_io_children(topology, gp_indexes, obj);
  hwloc__check_misc_children(topology, gp_indexes, obj);
  hwloc__check_children_cpusets(topology, obj);
  
}

static void
hwloc__check_nodesets(hwloc_topology_t topology, hwloc_obj_t obj, hwloc_bitmap_t parentset)
{
  hwloc_obj_t child;
  int prev_first;

  if (obj->type == HWLOC_OBJ_NUMANODE) {
    
    assert(hwloc_bitmap_weight(obj->nodeset) == 1);
    assert(hwloc_bitmap_first(obj->nodeset) == (int) obj->os_index);
    assert(hwloc_bitmap_weight(obj->complete_nodeset) == 1);
    assert(hwloc_bitmap_first(obj->complete_nodeset) == (int) obj->os_index);
    if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED)) {
      assert(hwloc_bitmap_isset(topology->allowed_nodeset, (int) obj->os_index));
    }
    assert(!obj->arity);
    assert(!obj->memory_arity);
    assert(hwloc_bitmap_isincluded(obj->nodeset, parentset));
  } else {
    hwloc_bitmap_t myset;
    hwloc_bitmap_t childset;

    
    myset = hwloc_bitmap_alloc();
    for_each_memory_child(child, obj) {
      assert(!hwloc_bitmap_intersects(myset, child->nodeset));
      hwloc_bitmap_or(myset, myset, child->nodeset);
    }
    
    assert(!hwloc_bitmap_intersects(myset, parentset));
    hwloc_bitmap_or(parentset, parentset, myset);
    hwloc_bitmap_free(myset);
    

    
    childset = hwloc_bitmap_alloc();
    for_each_child(child, obj) {
      hwloc_bitmap_t set = hwloc_bitmap_dup(parentset); 
      hwloc__check_nodesets(topology, child, set);
      
      hwloc_bitmap_andnot(set, set, parentset);
      
      assert(!hwloc_bitmap_intersects(childset, set));
      hwloc_bitmap_or(childset, childset, set);
      hwloc_bitmap_free(set);
    }
    
    assert(!hwloc_bitmap_intersects(parentset, childset));
    hwloc_bitmap_or(parentset, parentset, childset);
    hwloc_bitmap_free(childset);
    
    assert(hwloc_bitmap_isequal(obj->nodeset, parentset));
  }

  
  prev_first = -1; 
  for_each_memory_child(child, obj) {
    int first = hwloc_bitmap_first(child->complete_nodeset);
    assert(prev_first < first);
    prev_first = first;
  }
}

static void
hwloc__check_level(struct hwloc_topology *topology, int depth,
		   hwloc_obj_t first, hwloc_obj_t last)
{
  unsigned width = hwloc_get_nbobjs_by_depth(topology, depth);
  struct hwloc_obj *prev = NULL;
  hwloc_obj_t obj;
  unsigned j;

  
  for(j=0; j<width; j++) {
    obj = hwloc_get_obj_by_depth(topology, depth, j);
    
    assert(obj);
    assert(obj->depth == depth);
    assert(obj->logical_index == j);
    
    if (prev) {
      assert(hwloc_type_cmp(obj, prev) == HWLOC_OBJ_EQUAL);
      assert(prev->next_cousin == obj);
    }
    assert(obj->prev_cousin == prev);

    
    if (obj->type == HWLOC_OBJ_NUMANODE) {
      assert(hwloc_bitmap_weight(obj->complete_nodeset) == 1);
      assert(hwloc_bitmap_first(obj->complete_nodeset) == (int) obj->os_index);
    }
    prev = obj;
  }
  if (prev)
    assert(prev->next_cousin == NULL);

  if (width) {
    
    obj = hwloc_get_obj_by_depth(topology, depth, 0);
    assert(obj);
    assert(!obj->prev_cousin);
    
    assert(hwloc_get_depth_type(topology, depth) == obj->type);
    assert(depth == hwloc_get_type_depth(topology, obj->type)
	   || HWLOC_TYPE_DEPTH_MULTIPLE == hwloc_get_type_depth(topology, obj->type));
    
    obj = hwloc_get_obj_by_depth(topology, depth, width-1);
    assert(obj);
    assert(!obj->next_cousin);
  }

  if (depth < 0) {
    assert(first == hwloc_get_obj_by_depth(topology, depth, 0));
    assert(last == hwloc_get_obj_by_depth(topology, depth, width-1));
  } else {
    assert(!first);
    assert(!last);
  }

  
  obj = hwloc_get_obj_by_depth(topology, depth, width);
  assert(!obj);
}


void
hwloc_topology_check(struct hwloc_topology *topology)
{
  struct hwloc_obj *obj;
  hwloc_bitmap_t gp_indexes, set;
  hwloc_obj_type_t type;
  unsigned i;
  int j, depth;

  

  
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_L2CACHE == HWLOC_OBJ_L1CACHE + 1);
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_L3CACHE == HWLOC_OBJ_L2CACHE + 1);
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_L4CACHE == HWLOC_OBJ_L3CACHE + 1);
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_L5CACHE == HWLOC_OBJ_L4CACHE + 1);
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_L1ICACHE == HWLOC_OBJ_L5CACHE + 1);
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_L2ICACHE == HWLOC_OBJ_L1ICACHE + 1);
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_L3ICACHE == HWLOC_OBJ_L2ICACHE + 1);

  
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_NUMANODE   + 1 == HWLOC_OBJ_BRIDGE);
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_BRIDGE     + 1 == HWLOC_OBJ_PCI_DEVICE);
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_PCI_DEVICE + 1 == HWLOC_OBJ_OS_DEVICE);
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_OS_DEVICE  + 1 == HWLOC_OBJ_MISC);
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_MISC       + 1 == HWLOC_OBJ_MEMCACHE);
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_MEMCACHE   + 1 == HWLOC_OBJ_DIE);
  HWLOC_BUILD_ASSERT(HWLOC_OBJ_DIE        + 1 == HWLOC_OBJ_TYPE_MAX);

  
  HWLOC_BUILD_ASSERT(sizeof(obj_type_order)/sizeof(*obj_type_order) == HWLOC_OBJ_TYPE_MAX);
  HWLOC_BUILD_ASSERT(sizeof(obj_order_type)/sizeof(*obj_order_type) == HWLOC_OBJ_TYPE_MAX);
  HWLOC_BUILD_ASSERT(sizeof(obj_type_priority)/sizeof(*obj_type_priority) == HWLOC_OBJ_TYPE_MAX);

  
  assert(topology->type_filter[HWLOC_OBJ_GROUP] != HWLOC_TYPE_FILTER_KEEP_ALL);

  
  for(type=HWLOC_OBJ_TYPE_MIN; type<HWLOC_OBJ_TYPE_MAX; type++)
    assert(obj_order_type[obj_type_order[type]] == type);
  for(i=HWLOC_OBJ_TYPE_MIN; i<HWLOC_OBJ_TYPE_MAX; i++)
    assert(obj_type_order[obj_order_type[i]] == i);

  if (!topology->is_loaded)
    return;

  depth = hwloc_topology_get_depth(topology);

  assert(!topology->modified);

  
  assert(hwloc_get_depth_type(topology, 0) == HWLOC_OBJ_MACHINE);

  
  assert(hwloc_get_depth_type(topology, depth-1) == HWLOC_OBJ_PU);
  assert(hwloc_get_nbobjs_by_depth(topology, depth-1) > 0);
  for(i=0; i<hwloc_get_nbobjs_by_depth(topology, depth-1); i++) {
    obj = hwloc_get_obj_by_depth(topology, depth-1, i);
    assert(obj);
    assert(obj->type == HWLOC_OBJ_PU);
    assert(!obj->memory_first_child);
  }
  
  for(j=1; j<depth-1; j++) {
    assert(hwloc_get_depth_type(topology, j) != HWLOC_OBJ_PU);
    assert(hwloc_get_depth_type(topology, j) != HWLOC_OBJ_MACHINE);
  }

  
  for(j=0; j<depth; j++) {
    int d;
    type = hwloc_get_depth_type(topology, j);
    assert(type != HWLOC_OBJ_NUMANODE);
    assert(type != HWLOC_OBJ_MEMCACHE);
    assert(type != HWLOC_OBJ_PCI_DEVICE);
    assert(type != HWLOC_OBJ_BRIDGE);
    assert(type != HWLOC_OBJ_OS_DEVICE);
    assert(type != HWLOC_OBJ_MISC);
    d = hwloc_get_type_depth(topology, type);
    assert(d == j || d == HWLOC_TYPE_DEPTH_MULTIPLE);
  }

  
  for(type=HWLOC_OBJ_TYPE_MIN; type<HWLOC_OBJ_TYPE_MAX; type++) {
    int d;
    d = hwloc_get_type_depth(topology, type);
    if (type == HWLOC_OBJ_NUMANODE) {
      assert(d == HWLOC_TYPE_DEPTH_NUMANODE);
      assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_NUMANODE);
    } else if (type == HWLOC_OBJ_MEMCACHE) {
      assert(d == HWLOC_TYPE_DEPTH_MEMCACHE);
      assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_MEMCACHE);
    } else if (type == HWLOC_OBJ_BRIDGE) {
      assert(d == HWLOC_TYPE_DEPTH_BRIDGE);
      assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_BRIDGE);
    } else if (type == HWLOC_OBJ_PCI_DEVICE) {
      assert(d == HWLOC_TYPE_DEPTH_PCI_DEVICE);
      assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_PCI_DEVICE);
    } else if (type == HWLOC_OBJ_OS_DEVICE) {
      assert(d == HWLOC_TYPE_DEPTH_OS_DEVICE);
      assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_OS_DEVICE);
    } else if (type == HWLOC_OBJ_MISC) {
      assert(d == HWLOC_TYPE_DEPTH_MISC);
      assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_MISC);
    } else {
      assert(d >=0 || d == HWLOC_TYPE_DEPTH_UNKNOWN || d == HWLOC_TYPE_DEPTH_MULTIPLE);
    }
  }

  
  assert(hwloc_get_nbobjs_by_depth(topology, 0) == 1);
  obj = hwloc_get_root_obj(topology);
  assert(obj);
  assert(!obj->parent);
  assert(obj->cpuset);
  assert(!obj->depth);

  
  if (topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED) {
    assert(hwloc_bitmap_isincluded(topology->allowed_cpuset, obj->cpuset));
    assert(hwloc_bitmap_isincluded(topology->allowed_nodeset, obj->nodeset));
  } else {
    assert(hwloc_bitmap_isequal(topology->allowed_cpuset, obj->cpuset));
    assert(hwloc_bitmap_isequal(topology->allowed_nodeset, obj->nodeset));
  }

  
  for(j=0; j<depth; j++)
    hwloc__check_level(topology, j, NULL, NULL);
  for(j=0; j<HWLOC_NR_SLEVELS; j++)
    hwloc__check_level(topology, HWLOC_SLEVEL_TO_DEPTH(j), topology->slevels[j].first, topology->slevels[j].last);

  
  gp_indexes = hwloc_bitmap_alloc(); 
  hwloc__check_object(topology, gp_indexes, obj);
  hwloc_bitmap_free(gp_indexes);

  
  set = hwloc_bitmap_alloc();
  hwloc__check_nodesets(topology, obj, set);
  hwloc_bitmap_free(set);
}

#else 

void
hwloc_topology_check(struct hwloc_topology *topology __hwloc_attribute_unused)
{
}

#endif 
